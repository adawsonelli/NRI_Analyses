{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"OptTop\"></a>\n",
    "# Optimizers\n",
    "\n",
    " * This notebook serves as a library of optimizer classes that may be supplied with an objective function and boundary constraints\n",
    " * provides a set of test functions to visualize optimizer performance\n",
    "\n",
    "## [Optimizer Interface](#OptInterface)\n",
    " - interface for each optimization class to follow\n",
    "\n",
    "## [Optimization Algorithm Visualizer](#AlgVis)\n",
    " - set of 2D example problems which can be:\n",
    " - solved\n",
    " - visualied\n",
    " - with any samplin based opt method\n",
    " \n",
    "## [Baysian Optimization](#bayes)\n",
    " - surogate model method\n",
    " - very sample efficient\n",
    " \n",
    "## [Simulated Annealing](#SA)\n",
    " - implemented from scratch\n",
    " - gradually lower temp to choose between best and current sample\n",
    "\n",
    "## [DIRECT Algorithm](#DIRECT)\n",
    " - global method based on partitioning parameter space hypercube\n",
    "\n",
    "## [Covariance Matrix Adaptation (CMA)](#CMA)\n",
    " - evolutionary strategy \n",
    " \n",
    "## [Notes](#Notes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the notebook is being used as a library, or being run as a notebook\n",
    "asLibrary = lambda : '__file__' in globals()\n",
    "if asLibrary():\n",
    "    print(\"optimizers run as library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"OptInterface\"></a>\n",
    "# Optimizer Interface [ &#x21ea;](#OptTop)\n",
    "to maitain a level of decoupling between elements of the software system, the optimizer will not be given access to the robot or the experiment explicitly, but will deal instead  only with function handles for the objective function and constraint functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimization interface here\n",
    "class Opt:\n",
    "    \"\"\"\n",
    "    defines the interface that all types of optimizer should follow\n",
    "    \"\"\"\n",
    "    def optimize(self,obj,bounds,constraints=None,x0=None):\n",
    "        \"\"\"\n",
    "        the function which actually performs the optimization or sampling\n",
    "        inputs:\n",
    "            obj - a function handle from exp.objective\n",
    "            bounds - an function handle which returns a [nx2] (tall) np.array of box constraints\n",
    "            constraints - a list of function handles to hard constraint functions (to be implemented)\n",
    "            x0 - a guess for the location of xBest, used by some algorithms to initiate the optimization\n",
    "        outputs:\n",
    "            x - a list of np.array objects, each of which is a solution\n",
    "                list of the parameter for the optimal solution\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"AlgVis\"></a>\n",
    "# Optimization Algorithm Visualizer [ &#x21ea;](#OptTop)\n",
    "\n",
    "* pick from a set of test functions, visualize how that optimizer works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class OptimAlgVis():\n",
    "    \"\"\"\n",
    "    Optimization Algorithm Visualizer - test out the performance a sampling based\n",
    "    optimization algorithm on a set of test objective functions\n",
    "    \"\"\"\n",
    "    def __init__(self,opt,nSamps=1000):\n",
    "        #-------------- test function and opt setup -------------\n",
    "        self.opt = opt               # handle to the optimization algorithm object\n",
    "        self.nSamps = nSamps         # how many samples to take\n",
    "        self.data = []               # where you will store the samples leading upto the optimal point\n",
    "        \n",
    "        #import the test functions from landscapes library\n",
    "        from landscapes.single_objective import  ackley\n",
    "        from landscapes.single_objective import  eggholder\n",
    "        from landscapes.single_objective import  himmelblau\n",
    "        \n",
    "        # list of test function handles to evaluate the optimizer on\n",
    "        self.testFunctions = \\\n",
    "        [\n",
    "            ackley,\n",
    "            eggholder,\n",
    "            himmelblau,\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        #names of test functions\n",
    "        self.tfNames = {\"ackley\":0,\"eggholder\":1,\"himmelblau\":2}\n",
    "        \n",
    "        #current test function (state)\n",
    "        self.tf = None                     # init at call time of plot \n",
    "        self.tfid = None                   # id of the test function updated at call time\n",
    "        \n",
    "        #list of test fxn bounds\n",
    "        self.testFunctionBounds = \\\n",
    "        [\n",
    "            np.array([[-5,5],          # ackley\n",
    "                      [-5,5]]),\n",
    "            np.array([[-512,512],      # eggholder\n",
    "                      [-512,512]]),\n",
    "            np.array([[-5,5],          # himmelblau\n",
    "                      [-5,5]]),\n",
    "        ]\n",
    "        \n",
    "        #list of global optima for comparison\n",
    "        self.globalOptima = \\\n",
    "        [\n",
    "            [(0,0),0],                      # ackley\n",
    "            [(512, 404.2319), -959.6407],   # eggholder\n",
    "            [(3.0,2.0),0]                   # himmelblau (there are 4 global solutions, consider plotting all of them)\n",
    "        ]\n",
    "        \n",
    "        #------------- visualization setup ---------------------\n",
    "        self.figl = go.FigureWidget()\n",
    "        self.figl.add_trace(go.Scatter3d(z=[0],x=[0],y=[0], name = \"sampling\",mode=\"markers\",\n",
    "                                                marker = dict(size=10,color = np.linspace(0,1,self.nSamps))))\n",
    "        self.figr = go.FigureWidget()\n",
    "        self.figr.add_trace(go.Scatter(x=[], y=[],mode = \"markers\"))\n",
    "        \n",
    "        s2s = widgets.IntSlider(min=1,max=self.nSamps,value=1,description='show')\n",
    "        n   = widgets.IntSlider(min=1,max=self.nSamps,value=1,description='n')\n",
    "        self.wdict = {\"s2s\":s2s,\"n\":n}\n",
    "        \n",
    "        self.figr.update_layout(\n",
    "            #autosize=False,\n",
    "            #width = 1400,\n",
    "            height= 800,\n",
    "            legend=dict(x=.025, y=.975),\n",
    "            margin=dict(l=0, r=20, t=0, b=0))\n",
    "        \n",
    "        self.figr.update_layout(\n",
    "            #autosize=False,\n",
    "            #width = 1400,\n",
    "            height= 800,\n",
    "            legend=dict(x=.025, y=.975),\n",
    "            margin=dict(l=100, r=100, t=200, b=150))\n",
    "        \n",
    "        \n",
    "    def bounds(self):\n",
    "        \"\"\"\n",
    "        a function which returns the correct bounds np.array object, given that the \n",
    "        internal state of which test function is active\n",
    "        \"\"\"\n",
    "        return self.testFunctionBounds[self.tfid]\n",
    "        \n",
    "    def obj(self,x,grad=0):\n",
    "        \"\"\"\n",
    "        objective function of the currently selected test function, which has \n",
    "        the side effect of writing [x, fx] into a databuffer for visualization\n",
    "        \"\"\"\n",
    "        fx = self.tf(x)\n",
    "        sln = list(x.copy())\n",
    "        sln.append(fx)\n",
    "        self.data.append(sln)\n",
    "        return fx\n",
    "        \n",
    "    #----------------- visualization functions -------------------\n",
    "    def plotTestFxn3D(self,fxnName):\n",
    "        #extract function and assoicated objects\n",
    "        fid = self.tfNames[fxnName]\n",
    "        fxn = self.testFunctions[fid]\n",
    "        b = self.testFunctionBounds[fid]\n",
    "        \n",
    "        # Generate data\n",
    "        x = np.linspace(b[0,0],b[0,1] , 100)\n",
    "        y = np.linspace(b[1,0],b[1,1] , 100)\n",
    "        xGrid, yGrid = np.meshgrid(y, x)\n",
    "        \n",
    "        # define a function and vectorize it \n",
    "        # for simple application over a meshgrid\n",
    "        @np.vectorize\n",
    "        def vFunc(x,y,fxn):\n",
    "            return fxn((x,y))\n",
    "        \n",
    "        #evaluate z\n",
    "        z = vFunc(xGrid, yGrid,fxn)\n",
    "\n",
    "        # adding surfaces to subplots.\n",
    "        self.figl.add_trace(go.Surface(x=x, y=y, z=z, colorscale='Viridis', showscale=False))\n",
    "        \n",
    "    def getSamps(self,s2s,n):\n",
    "        rng = range(n,n+s2s)\n",
    "        xs = self.data[rng,0]\n",
    "        ys = self.data[rng,1]\n",
    "        zs = self.data[rng,2]\n",
    "        return xs,ys,zs\n",
    "\n",
    "    def update(self,s2s= 10,n=1):\n",
    "        \n",
    "        figl = self.figl\n",
    "        with figl.batch_update():\n",
    "            #get the sampled points\n",
    "            xs,ys,zs = self.getSamps(s2s,n)\n",
    "            \n",
    "            figl.data[0]['x']= xs\n",
    "            figl.data[0]['y']= ys\n",
    "            figl.data[0]['z']= zs\n",
    "            \n",
    "        figr = self.figr\n",
    "        with figr.batch_update():\n",
    "            figr.data[0]['x']= xs\n",
    "            figr.data[0]['y']= ys\n",
    "            \n",
    "            \n",
    "    def disp(self):\n",
    "        self.out = widgets.interactive_output(self.update, self.wdict)\n",
    "        display(self.wdict[\"s2s\"])\n",
    "        display(self.wdict[\"n\"])\n",
    "        sideBySide = widgets.HBox([self.figl,self.figr])\n",
    "        display(sideBySide)\n",
    " \n",
    "\n",
    "    #------------------- interface ----------------\n",
    "    def plot(self,fxnName = \"ackley\"):\n",
    "        \"\"\"\n",
    "        call this function to test and plot the landscape and the sample points\n",
    "        for the specified optmization algorithm\n",
    "        input:\n",
    "            fxn2plot, which of the test functions should be plotted?\n",
    "        \"\"\"\n",
    "        # register the test function with self\n",
    "        tfid = self.tfNames[fxnName]\n",
    "        self.tf = self.testFunctions[tfid]\n",
    "        self.tfid = tfid\n",
    "        \n",
    "        # setup the optimizer with the test function and perform optimization\n",
    "        self.opt.nSamps = self.nSamps\n",
    "        self.opt.optimize(self.obj,self.bounds)\n",
    "        self.data = np.array(self.data)   #turn cached data into an array\n",
    "        \n",
    "        #---- setup the visualizer -------\n",
    "        \n",
    "        #plot the test fxn in 3D\n",
    "        self.plotTestFxn3D(fxnName)\n",
    "        \n",
    "        #setup the bounds of the sampling plot\n",
    "        b = self.testFunctionBounds[tfid]\n",
    "        self.figr.update_xaxes(range=[b[0,0], b[0,1]])\n",
    "        self.figr.update_yaxes(range=[b[1,0], b[1,1]])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #plot the interactive visualization\n",
    "        self.disp()\n",
    "        \n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sobol sampling\n",
    "\n",
    "\n",
    "#### refs:\n",
    "https://people.sc.fsu.edu/~jburkardt/py_src/sobol/sobol.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd09148d6fd476cb586a7199883cb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='samps', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98e2c5ed1c74d419b8981642b8a3681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.      , 0.001001, 0.002002, ..., 0.997998, 0.998999,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sobol import i4_sobol\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "class Sobol:\n",
    "    \"\"\"\n",
    "    the sobol opt class \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.n = 1000          #number of samples to evaluate\n",
    "        self.nBest = 10        #number to keep\n",
    "        self.xBest = []        #list of nBest x values\n",
    "        self.fxBest = []       #list of nBest obj function values\n",
    "        self.randomSeed = True #should sample seed be randomized?\n",
    "        \n",
    "        self.selectionFxn = \"max_fx\" #str name of selection fxn [\"max_fx\", \"obj_var_tradeoff\"]\n",
    "        self.W_obj = 1                #importance parameter for objective fxn\n",
    "        self.W_dispersion = 1         #importance parameter for dispersion metric \n",
    "        \n",
    "        self.xs = []                  #n x's\n",
    "        self.fxs = []                 #n solutions\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def twoPointLine(x,x1,y1,x2,y2):\n",
    "        \"\"\"returns y given the formula of a line specified in 2 point form\"\"\"\n",
    "        return ((y2-y1)/(x2-x1))*(x - x1) + y1\n",
    "    \n",
    "    @staticmethod\n",
    "    def Sample(bounds,n,randomSeed = True):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "            bounds - [nx2] array of [max,min]\n",
    "            n - number of sample points requested\n",
    "            randomSeed - bool - start in a place other than 0\n",
    "        outputs:\n",
    "            samps - list of np.arrays  (so you can interate through them more easily)\n",
    "        \"\"\"\n",
    "        #calc the sobol inputs\n",
    "        ndims = bounds.shape[0]\n",
    "        upperbounds = bounds[:,0] ; lowerbounds = bounds[:,1]\n",
    "        if randomSeed: seed_0 = np.random.randint(0,10000)\n",
    "        else: seed_0 = 0\n",
    "        \n",
    "        #sample the unit hypercube\n",
    "        samps = [i4_sobol(ndims, seed)[0] for seed in range(seed_0,n + seed_0)]\n",
    "        #samps = np.array(samps)\n",
    "        \n",
    "        #shift and scale from the unit hypercube to the bounds rectangular prism\n",
    "        sl = []  #samps list\n",
    "        for sample in samps:\n",
    "            sn = np.zeros(ndims)  #sample new\n",
    "            for i,x in enumerate(sample):\n",
    "                x1 = 0 ; x2 = 1\n",
    "                y1 = lowerbounds[i] ; y2 = upperbounds[i]\n",
    "                sn[i] = Sobol.twoPointLine(x,x1,y1,x2,y2)\n",
    "            sl.append(sn)\n",
    "        \n",
    "        return sl\n",
    "    \n",
    "    \n",
    "    #------------------ selection fxns ------------------------\n",
    "    def max_fx(self):\n",
    "        \"\"\"\n",
    "        return the nBest results based only on the value of Fx\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def re_sample(self):\n",
    "        pass\n",
    "    \n",
    "    def histSelect(self):\n",
    "        \"\"\"\n",
    "        randomly select solutions from the top percent,and place them in the xBest\n",
    "        and fxBest\n",
    "        \"\"\"\n",
    "        nbest = 10\n",
    "        ids = np.argsort(self.fxs)[::-1][:nbest]\n",
    "        \n",
    "        #place best solutions into list\n",
    "        self.xBest  = [self.xs[i]  for i in ids]\n",
    "        self.fxBest = [self.fxs[i] for i in ids]\n",
    "    \n",
    "    #------------------- optimization --------------------------\n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \"\"\"\n",
    "       discover interesting and good solutions at different locations within the space, \n",
    "       no optimization is performed strictly speaking, just structured exploration\n",
    "        \"\"\"\n",
    "        self.xs = Sobol.Sample(bounds,self.n,self.randomSeed)\n",
    "        self.fxs = [] \n",
    "        for x in self.xs:\n",
    "            self.fxs.append(obj(x))\n",
    "        \n",
    "        return eval('self.' + self.selectionFxn + '()')\n",
    "\n",
    "\n",
    "class SobolVis:\n",
    "    \"\"\"\n",
    "    just want to get a sense for what sampling a unit space\n",
    "    using sobol sampling looks like\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        _fig = go.Figure(data=[go.Scatter3d(z=[0],x=[0],y=[0], name = \"sampling\",mode=\"markers\",\n",
    "                                            marker = dict(size=10,color = np.linspace(0,1,1000),showscale=True))])\n",
    "        self.fig = go.FigureWidget(_fig)\n",
    "        n = widgets.IntSlider(min=1,max=1000,value=1,description='samps')\n",
    "        self.wdict = {\"n\":n}\n",
    "        \n",
    "        self.fig.update_layout(\n",
    "            autosize=False,\n",
    "            width = 800,\n",
    "            height= 800,\n",
    "            legend=dict(x=.025, y=.975),\n",
    "            margin=dict(l=0, r=20, t=0, b=0))\n",
    "        \n",
    "    def genSamps(self,n):\n",
    "        #how to use sobol\n",
    "        bounds = np.array([[.5,1,-1],[.25,-1,-3]]).T\n",
    "        samps = Sobol.Sample(bounds,n,randomSeed = False)\n",
    "        #samps = [i4_sobol(dim_num, seed)[0] for seed in range(n)]\n",
    "        samps = np.array(samps)\n",
    "        xs = samps[:,0] ; ys = samps[:,1] ; zs = samps[:,2]\n",
    "        return xs,ys,zs\n",
    "    \n",
    "    \n",
    "    def update(self,n=1):\n",
    "        fig = self.fig\n",
    "        with fig.batch_update():\n",
    "            #plot n sobol points, with coloring\n",
    "            xs,ys,zs = self.genSamps(n)\n",
    "            \n",
    "            fig.data[0]['x']= xs\n",
    "            fig.data[0]['y']= ys\n",
    "            fig.data[0]['z']= zs\n",
    "            \n",
    "            \n",
    "    def disp(self):\n",
    "        self.out = widgets.interactive_output(self.update, self.wdict)\n",
    "        display(self.wdict[\"n\"])\n",
    "        display(self.fig)\n",
    "        \n",
    "\n",
    "#interactive 3D sobol sampling visualization to get a sense of the algorithm \n",
    "if not asLibrary() and True:\n",
    "    vis = SobolVis()\n",
    "    vis.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS \n",
    "Broyden–Fletcher–Goldfarb–Shanno (BFGS) is a quazi-newton optimization method that uses the secant approach to find stationary points via locating the zeros of the gradient (jacobian) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "class BFGS:\n",
    "    def __init__(self):\n",
    "        self.mode = \"seeded\"   #[\"seeded\",\"sobol\",\"SA\"] \n",
    "        self.n = 1             #number of starting points\n",
    "        self.x0 = []           #incase you want to prime the algorithm, from outside manipulation\n",
    "        self.xBest = []        #list of n x values\n",
    "        self.fxBest = []       #list of n obj function values\n",
    "        self.res = []          #results of most recent optimization\n",
    "        \n",
    "    def optimize(self,obj,bounds,constraints): #refactor to remove this code repetition.\n",
    "        \n",
    "        #specify the bounds:\n",
    "        bnds = Bounds(bounds[:,1],bounds[:,0],keep_feasible=True)\n",
    "        \n",
    "        #specify the fixed step size (epsilon):\n",
    "        eps = (bounds[:,0] - bounds[:,1])/10000\n",
    "        \n",
    "        #make a maximum into a minimum\n",
    "        min_obj = lambda x: -1 * obj(x)\n",
    "        \n",
    "        if self.mode == \"seeded\":\n",
    "            self.res = minimize(min_obj,\n",
    "                                self.x0[0],\n",
    "                                method='BFGS',\n",
    "                                jac = False,\n",
    "                                bounds = bnds,\n",
    "                                options={'gtol': 1e-3,\n",
    "                                         'disp': True,\n",
    "                                         'eps': eps})\n",
    "                                        #'finite_diff_rel_step':finite_diff_rel_step})\n",
    "            self.xBest.append(self.res.x)\n",
    "            self.fxBest.append(1)\n",
    "            \n",
    "        elif self.mode == \"sobol\":\n",
    "            samps = Sobol.Sample(bounds,self.n,randomSeed = True)\n",
    "            for x0 in samps:\n",
    "                self.res = minimize(obj, x0, method='BFGS',\n",
    "                           options={'gtol': 1e-6, 'disp': True})\n",
    "                self.xBest.append(self.res.x)\n",
    "                self.fxBest.append(1)\n",
    "        \n",
    "        return self.xBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bayes\"></a>\n",
    "# Baysian Optimization [ &#x21ea;](#OptTop)\n",
    "- optimization based on the formation of a surogate model of a gaussian process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7223deb5344eac99b6c3fde5ade6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='show', max=20, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78876122f0c4068bcda1a2e9bbac864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='n', max=20, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad545b24fc194d86a0f2d90a07132fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.        , 0.05263158, 0.10526316, 0.1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skopt import Optimizer as _bayesOpt\n",
    "\n",
    "\n",
    "class BayesOpt:\n",
    "    \"\"\"\n",
    "    a baysian optimization algorithm based on the formation of a surogate\n",
    "    model of a gaussian process\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.nSamps = 20\n",
    "        self.plotResults = False\n",
    "        \n",
    "    def optimize(self,obj,bnds,constraints=None,x0=None):\n",
    "        \n",
    "        #define boundary condition limits (lower,upper)\n",
    "        bounds = bnds().astype(float)  #cast to a float so that optimizer doesn't think this is an integer problem.\n",
    "        lb = bounds[:,0]\n",
    "        ub = bounds[:,1]\n",
    "        bounds = list(zip(lb,ub))\n",
    "\n",
    "        #run the optimization\n",
    "        opt = _bayesOpt(bounds, \"GP\", n_initial_points=10,acq_optimizer=\"sampling\")\n",
    "        for i in range(self.nSamps):\n",
    "            suggested = opt.ask()\n",
    "            y = obj(suggested)\n",
    "            res = opt.tell(suggested, y)\n",
    "        \n",
    "        #plots (could expand on this)\n",
    "        if self.plotResults:\n",
    "            from skopt.plots import plot_objective, plot_evaluations\n",
    "            plot_evaluations(res, bins=10)\n",
    "            plot_objective(res)\n",
    "        \n",
    "#visualizer performance on test functions\n",
    "if not asLibrary():\n",
    "    names = {0:\"ackley\",1:\"eggholder\",2:\"himmelblau\"}\n",
    "    alg = BayesOpt()\n",
    "    vis = OptimAlgVis(alg,nSamps=20)\n",
    "    vis.plot(names[0])\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SA\"></a>\n",
    "# Simulated Annealing [ &#x21ea;](#OptTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on iteration 0\n",
      "on iteration 100\n",
      "on iteration 200\n",
      "on iteration 300\n",
      "on iteration 400\n",
      "on iteration 500\n",
      "on iteration 600\n",
      "on iteration 700\n",
      "on iteration 800\n",
      "on iteration 900\n",
      "on iteration 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91790555e1b4a86b14c8b4954482fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='show', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7098f387ff491d9b04b56ed2775cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='n', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e52b834ef644f1cb5e11fe88ebddb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.      , 0.001001, 0.002002, ..., 0.99…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#simulated anealing algorithm must have the following functions: \n",
    "# the feasable state space\n",
    "# the Energetic function (which is the objective function) E()\n",
    "# the candidate generator procedure (neighbor(x))\n",
    "#        -generation of random candidate vector, with variable magnitude?\n",
    "#         aniostropic exploration is better!!!\n",
    "#thoughts for how I might solve this problem - \n",
    "#         boundry check or only sampling within the boundry seems a good strategy. \n",
    "#        -moving in one direction at at time. \n",
    "\n",
    "# acceptance probability function P()\n",
    "# anealing schedule - number, number of anealing cycles, cooling rate\n",
    "# some termination condition - total execution time or number of interations\n",
    "# presensce of and number of restarts, deterministic or otherwise? \n",
    "\n",
    "#of these, cooling schedule and neighbor seem the most important functions\n",
    "\n",
    "\n",
    "class SA:\n",
    "    def __init__(self):\n",
    "        self.nSamps = 1000;                    #total number of iterations to perform\n",
    "        self.nResets = 3                       #number of resets to best \n",
    "        self.brt = self._brt()                 #trial numbers during which to reset to best\n",
    "        self.dist = \"uniform\"                  #neighborhood sampling method \n",
    "        self.aMode = \"Exp\"                     #Annealing mode [\"exp\",\"linear\",\"stepped\"]\n",
    "        self.nMode = \"Linear\"                  #neighborhood Mode\n",
    "        self.T = 1                             #temperature variable on [1-0)\n",
    "        self.N = 1                             #neighborhood size coefficient [1-0)\n",
    "        self.C_half = 200                      #half-life cooling              [trials]\n",
    "        self.N_half = 150                      #half-life of neighborhood size [trials]\n",
    "        self.fxBest = 0                        #best encountered function value\n",
    "        self.xBest = []                        #location of best value\n",
    "        self.dbg = False                        #save variables for debugging\n",
    "        self.xCache  = []                      #storage for x\n",
    "        self.FxCache = []                      #storage for Fx\n",
    "        self.updateReports = True              #should we print out an update of how the optimization is progressing?\n",
    "        self.updateCount = 10                  #number of updates\n",
    "        \n",
    "        \n",
    "    def setBounds(self,bcs):\n",
    "        self.x_min = bcs[:,0]                  #upper limits on box constraints for x variable\n",
    "        self.x_max = bcs[:,1]                  #lower limits on box constraints for x variable\n",
    "        \n",
    "    def _center(self,x_max,x_min):\n",
    "        \"\"\"\n",
    "        find  the center of a box defined by limits\n",
    "        \"\"\"\n",
    "        return [(x_max[i] + x_min[i])/2 for i in range(len(x_max))]\n",
    "    \n",
    "    def _twoPointLine(self,x,x1,y1,x2,y2):\n",
    "        \"\"\"\n",
    "        returns y given the formula of a line specified in 2 point form\n",
    "        \"\"\"\n",
    "        return ((y2-y1)/(x2-x1))*(x - x1) + y1\n",
    "    \n",
    "    def _brt(self):\n",
    "        \"\"\"\n",
    "        calculate the best reset trials, evenly distribute in n_iter\n",
    "        \"\"\"\n",
    "        return np.random.randint(low  = int(self.nSamps/5),\n",
    "                                 high = self.nSamps,\n",
    "                                 size = self.nResets)\n",
    "        \n",
    "            \n",
    "    def sample(self,x):\n",
    "        \"\"\"\n",
    "        sample the space for the next sample based on the neighborhood\n",
    "        function\n",
    "        input:\n",
    "            x\n",
    "        output:\n",
    "            x_new\n",
    "        \"\"\"\n",
    "        #define the (ever-shrinking) neighborhood bounding box\n",
    "        w = self.N * ((self.x_max - self.x_min)) \n",
    "        nx_max = x + w\n",
    "        nx_min = x - w\n",
    "        \n",
    "        #define the combined bounding box as an intersection between\n",
    "        #the box constraints and the neighborhood box - a mini-max problem\n",
    "        cx_max = np.amin(np.vstack((self.x_max,nx_max)),axis = 0)\n",
    "        cx_min = np.amax(np.vstack((self.x_min,nx_min)),axis = 0)\n",
    "        \n",
    "#         for i in range(len(self.x_max)):\n",
    "#             cx_max[i] = min(self.x_max,nx_max[i])\n",
    "#             cx_min[i] = max(self.x_min,nx_min[i])\n",
    "        \n",
    "        #sample from the combined box, according to the appropriate distribution\n",
    "        if self.dist == \"uniform\": \n",
    "            x_new = np.random.uniform(cx_min,cx_max) #vectorized\n",
    "            \n",
    "        if self.dist == \"normal\":\n",
    "            pass\n",
    "#             zScore = 1.645 #95% confidence interval\n",
    "#             x_new = []\n",
    "#             while len(x_new) > len(self.x_min):\n",
    "#                 x = np.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "#                 if abs(x) < zScore:\n",
    "#                     x_new.append(x)\n",
    "#             c_range = cx_max - cx_min\n",
    "            \n",
    " \n",
    "        return x_new\n",
    "\n",
    "    def optimize(self,obj,bounds,constraints=None,x0=None):\n",
    "        \n",
    "        #set box constraints\n",
    "        bcs = bounds()\n",
    "        self.setBounds(bcs)\n",
    "        \n",
    "        #init x0 and fx0\n",
    "        x0 =  self._center(self.x_max,self.x_min)\n",
    "        fx0 = obj(x0)\n",
    "        \n",
    "        for n in range(self.nSamps + 1):\n",
    "            x = self.sample(x0)\n",
    "            fx = obj(x)\n",
    "            \n",
    "            #if better, always keep\n",
    "            if fx > fx0:\n",
    "                x0 = x ; fx0 = fx\n",
    "                \n",
    "            #probabalistically accept worse answer\n",
    "            else:\n",
    "                Δf = fx - fx0\n",
    "                r = np.random.random()\n",
    "                if r < np.exp(Δf/self.T):\n",
    "                    fx0 = fx ; x0 = x\n",
    "                    #print(x)\n",
    "                else:\n",
    "                    pass\n",
    "             \n",
    "            \n",
    "            #maintain best (for restarts, if used)\n",
    "            if fx > self.fxBest:\n",
    "                self.xBest = x  ; self.fxBest = fx \n",
    "                \n",
    "            #do a best restart:\n",
    "            if n in self.brt:\n",
    "                  x0 = self.xBest ; fx0 = self.fxBest \n",
    "            \n",
    "            #decrease temperature and neighborhood size\n",
    "            if self.aMode == \"Exp\": self.T = .5**(n/self.C_half)\n",
    "            if self.nMode == \"Exp\": self.N = .5**(n/self.N_half)\n",
    "            \n",
    "            if self.aMode == \"Linear\": self.T = self._twoPointLine(n,0,1,self.nSamps,0)\n",
    "            if self.nMode == \"Linear\": self.N = self._twoPointLine(n,0,1,self.nSamps,0)\n",
    "                  \n",
    "            #store debugging vars\n",
    "            if self.dbg:\n",
    "                self.xCache.append(x0[0])\n",
    "                self.FxCache.append(fx0[0])\n",
    "                \n",
    "            #give updates\n",
    "            if self.updateReports:\n",
    "                if n % ((self.nSamps) / 10) == 0:\n",
    "                    print(\"on iteration %d\" %n)\n",
    "            \n",
    "        return x0\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#visualizer performance on test functions\n",
    "if not asLibrary():\n",
    "    names = {0:\"ackley\",1:\"eggholder\",2:\"himmelblau\"}\n",
    "    alg = SA()\n",
    "    vis = OptimAlgVis(alg)\n",
    "    vis.plot(names[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"DIRECT\"></a>\n",
    "# DIRECT Algorithm [ &#x21ea;](#OptTop)\n",
    "\n",
    "the direct algorithm is a global optimization method that breaks up a bounded hyper-rectangle search space into progressively smaller and smaller sub-rectangles by identifying (via checking the center point of the rectangle) which areas of the input space are most prominsing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb2766aa0cc4d60811d9e914afbc5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='show', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaee04791d054b5097eb7a61bf966a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='n', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113850071c6b4684bdb813881220b192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.      , 0.001001, 0.002002, ..., 0.99…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nlopt\n",
    "\n",
    "class NLopt:\n",
    "    \"\"\"\n",
    "    container class which set's up the default configuration for a \n",
    "    NLopt algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self,method = \"DIRECT_L\"):\n",
    "        \n",
    "        #simulation parameters which can be configured during experiment\n",
    "        self.nSamps = 10000;                                                 # total number of samples to take\n",
    "        if method == \"DIRECT_L\": self.algorithm = \"GN_DIRECT_L\"              # default NLopt algorithm direct w/ local bias\n",
    "        elif method == \"DIRECT\": self.algorithm = \"GN_DIRECT\"                # DIRECT algorithm\n",
    "        elif method == \"CRS\"   : self.algorithm = 'GN_CRS2_LM'               # CRS\n",
    "        elif method == \"ES\"    : self.algorithm = 'GN_ISRES'                 # evolutionary strategy\n",
    "        elif method == \"EA\"    : self.algorithm = 'GN_ESCH'                  # evolutionary algorithm\n",
    "        \n",
    "        \n",
    "    def optimize(self,obj,bnds,constraints=None,x0=None):\n",
    "        \n",
    "        #init the optimization object\n",
    "        bounds = bnds()                             # get bounds array\n",
    "        n = bounds.shape[1]                         # number of parameters\n",
    "        \n",
    "        #setup optimizer interface\n",
    "        alg = eval(\"nlopt.\" + self.algorithm)\n",
    "        opt = nlopt.opt(alg, n)\n",
    "\n",
    "        #set bound constraints\n",
    "        opt.set_lower_bounds(bounds[:,0])\n",
    "        opt.set_upper_bounds(bounds[:,1])\n",
    "\n",
    "        #set the stop value\n",
    "        opt.set_maxeval(self.nSamps)\n",
    "\n",
    "        #register the objective function\n",
    "        #opt.set_max_objective(obj)\n",
    "        opt.set_min_objective(obj)\n",
    "\n",
    "        #execute optimization\n",
    "        if not x0: x0 = [np.random.uniform(bounds[i,0],bounds[i,1]) for i in range(n)]\n",
    "        xopt = opt.optimize(x0)\n",
    "        \n",
    "        #return optimization results\n",
    "        result = opt.last_optimize_result()\n",
    "        return xopt\n",
    "\n",
    "\n",
    "        \n",
    "#visualizer performance on test functions\n",
    "if not asLibrary():\n",
    "    names = {0:\"ackley\",1:\"eggholder\",2:\"himmelblau\"}\n",
    "    alg = NLopt()\n",
    "    vis = OptimAlgVis(alg)\n",
    "    vis.plot(names[2])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CMA\"></a>\n",
    "# Covariance Matrix Adaptation (CMA) [ &#x21ea;](#OptTop)\n",
    "\n",
    "* description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.81481481 4.81481481]\n",
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=367358, Mon Mar  8 21:00:03 2021)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aaca0b44d74d509ab4bdcd7fb439d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='show', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1cf315ec22404fb135eae4c7fe3730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='n', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867a922bccf84f31923ad151dd1b0ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.      , 0.001001, 0.002002, ..., 0.99…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cma\n",
    "\n",
    "# notes on CMA\n",
    "# there appears to be a need to scale the problem (by the bounds) such that the solution is within 3 sigma,\n",
    "# and one value of sigma is sufficient for each variable, meaning that x should be scaled?? \n",
    "# use CMAevolutionaryStrategy interface. - loop control stays with user\n",
    "# reading indicates it might be a good idea to repeat an optimization multiple times with an increaseing population schedule?\n",
    "# there seems to be a bit of an art to using this algorithm... return to this at a later date perhaps?\n",
    "\n",
    "\n",
    "# this is still a work in progress, as boundries are not well implemented, however for now we can ICE this, as we have more than enough other implementations\n",
    "\n",
    "\n",
    "\n",
    "class CMA: \n",
    "    def __init__(self):\n",
    "        self.popSize = 100\n",
    "        self.generations = 10 \n",
    "        self.nSamps = self.popSize * self.generations\n",
    "        self.mcPrime = True       # MonteCarlo Prime for x0?\n",
    "        self.mcSamps = 100        # MonteCarlo Samples\n",
    "        self.σ = 2                # 1/5th of solution space\n",
    "        self.lb = None            # init this when optimize gets called\n",
    "        self.ub = None            # init this when optimize gets called\n",
    "        \n",
    "    def scale(self,x):\n",
    "        \"\"\"\n",
    "        perform a linear scaling from a point in the problem domain\n",
    "        to a point in a scaled domain, xscl\n",
    "        inputs: \n",
    "            x - a point in the problem domain in Rn\n",
    "        outputs: \n",
    "            xscl - a point defined on [0-10] over n dimensions\n",
    "        \"\"\"\n",
    "        return self.lb + (self.ub-self.lb) * x / 10  # vectorized expression w/ elementwise operations\n",
    "            \n",
    "        \n",
    "    def scaleInv(self,xscl):\n",
    "        \"\"\"\n",
    "        perform an inverse operation to self.scale, moving from the \n",
    "        scaled domain to the original problem domain\n",
    "        inputs: \n",
    "            xscl - a point defined on [0-10] over n dimensions\n",
    "        outputs:\n",
    "            x - a point in the problem domain in Rn\n",
    "        \"\"\"\n",
    "        return (xscl - self.lb)*10 / (self.ub-self.lb) # vectorized expression w/ elementwise operations\n",
    "        \n",
    "    \n",
    "    def objWrap(self,obj):\n",
    "        \"\"\"\n",
    "        wrap the objective function in an invScale function\n",
    "        so that it's dealing with vlues in the proper domain\n",
    "        \"\"\"\n",
    "        def wrap(x,grad=None):\n",
    "            x = self.scaleInv(x)\n",
    "            return obj(x)\n",
    "        return wrap\n",
    "        \n",
    "    \n",
    "    def optimize(self,obj,bnds,constraints=None,x0 = None):\n",
    "        \n",
    "        #prime with Monte-carlo samples to get x0\n",
    "        if self.mcPrime == True and x0 == None:\n",
    "            primeAlg = NLopt()\n",
    "            primeAlg.nSamps = self.mcSamps\n",
    "            x0 = primeAlg.optimize(obj,bnds)\n",
    "            print(x0)\n",
    "        \n",
    "        #setup the lower and upper bounds in internal object\n",
    "        bounds = bnds()\n",
    "        self.lb = bounds[:,0]\n",
    "        self.ub = bounds[:,1]\n",
    "        \n",
    "        \n",
    "        #setup the bounds of the algorithm in the scaled domain\n",
    "        opts = {'bounds':[0,10]}\n",
    "        \n",
    "        \n",
    "        #wrap the objective function so that the assumption that every var is on [0-10] is valid\n",
    "        obj_w = self.objWrap(obj)\n",
    "        \n",
    "        #set other termination criteria\n",
    "        \n",
    "        #run the optimization\n",
    "        es = cma.CMAEvolutionStrategy(x0, self.σ,opts)\n",
    "        i = 0\n",
    "        while not es.stop() and i < self.generations:\n",
    "            solutions = es.ask()\n",
    "            es.tell(solutions, [obj_w(s) for s in solutions])\n",
    "            #es.disp()\n",
    "            i += 1 \n",
    "            #es.result_pretty()\n",
    "        return self.scale(es.result[0])\n",
    "            \n",
    "\n",
    "        \n",
    "#visualizer performance on test functions\n",
    "if not asLibrary():\n",
    "    names = {0:\"ackley\",1:\"eggholder\",2:\"himmelblau\"}\n",
    "    alg = CMA()\n",
    "    vis = OptimAlgVis(alg)\n",
    "    vis.plot(names[2])\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cma\n",
    "# #help(cma)  # \"this\" help message, use cma? in ipython\n",
    "# #help(cma.fmin)\n",
    "# help(cma.CMAEvolutionStrategy)\n",
    "\n",
    "# cma.CMAOptions('tol')  # display 'tolerance' termination options\n",
    "# cma.CMAOptions('verb') # display verbosity options\n",
    "# res = cma.fmin(cma.ff.tablet, 15 * [1], 1)\n",
    "# es = cma.CMAEvolutionStrategy(15 * [1], 1).optimize(cma.ff.tablet)\n",
    "# help(es.result)\n",
    "# res[0], es.result[0]  # best evaluated solution\n",
    "# res[5], es.result[5]  # mean solution, presumably better with noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Notes\"></a>\n",
    "# Notes: [ &#x21ea;](#OptTop)\n",
    "\n",
    "\n",
    "##  optimizer revamp plan of action\n",
    "\n",
    "### to do's: \n",
    "\n",
    "\n",
    "* finish CMA class with scale wrapper and connect to visualizer\n",
    "* select 2- 3  more optimizers from NLopt, and make a way to easily change between them, with iterations as the termination criteria.\n",
    "* ~Strike~\n",
    "* ~finish the outline of the optimizers library~\n",
    "* ~build the DIRECT class~\n",
    "* finish up some CMA notes\n",
    "* implement CMA to the point where you can run the 2D test functions, but don't implement the objective function rescaleing yet, you can do that at some future point\n",
    "* finish the test function visualizer, and then visualize the three optimization algorithms\n",
    "* change the way that torque is parameterized. this will take a bit of thinking, but I believe the best way to do it is to have a function that trades off torque between the right and left motors. the reason to do this is that if you allow 2 prameters for torque, then it will always be beneficial to add torque. we proposed normalization as a way to address this, and that still might be reasonable, but if we dont have normalization, perhaps we could have a torque budget(200nm) and then the algorithm could trade off additively. between the two torques. x + y = 100 we could then titrate this in, to see where we stop getting additional value from adding more system torque capability, and also if the ratios stay similar (i feel like they should, but who knows?)\n",
    "* integrate optimizers back into experiment, and start setting up some experiments in ExpsForPaper, including torque experiments. \n",
    "* once you have a feel for how these exps are turning out, it's time to plan out the figs for the paper, and the story for the prelim.\n",
    "\n",
    "\n",
    "\n",
    "### plan:\n",
    "\n",
    "* leave BDGS and Sobol here for now, there isn't a point in getting rid of them yet, and they might be useful.\n",
    "* end objective: 3 optimization classes, and a visualizer class that takes a handle to an optimizer, and a 2D example function, and a number of iterations, and plots points over time. \n",
    "* total time - 4 - 6 hours\n",
    "* visualizer - 2.5 hrs\n",
    "* DIRECT and CMA classes - 2hrs\n",
    "* 1hr to tie it all together \n",
    "* 10min clean up\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
