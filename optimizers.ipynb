{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baysian optimization\n",
    "\n",
    "#### resources\n",
    "* https://gpflowopt.readthedocs.io/en/latest/notebooks/constrained_bo.html baysian optimization with constraints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of bayesian optimization for a 1d function from scratch\n",
    "from math import sin\n",
    "from math import pi\n",
    "from numpy import arange\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# objective function\n",
    "def objective(x, noise=0.1):\n",
    "    noise = normal(loc=0, scale=noise)\n",
    "    return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(X, return_std=True)\n",
    "\n",
    "# probability of improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "    # calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    mu = mu[:, 0]\n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "    return probs\n",
    "\n",
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, y, model):\n",
    "    # random search, generate random samples\n",
    "    Xsamples = random(100)\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = argmax(scores)\n",
    "    return Xsamples[ix, 0]\n",
    "\n",
    "# plot real observations vs surrogate function\n",
    "def plot(X, y, model):\n",
    "    # scatter plot of inputs and real objective function\n",
    "    pyplot.scatter(X, y)\n",
    "    # line plot of surrogate function across domain\n",
    "    Xsamples = asarray(arange(0, 1, 0.001))\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "    ysamples, _ = surrogate(model, Xsamples)\n",
    "    pyplot.plot(Xsamples, ysamples)\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "if test:\n",
    "    # sample the domain sparsely with noise\n",
    "    X = random(100)\n",
    "    y = asarray([objective(x) for x in X])\n",
    "    # reshape into rows and cols\n",
    "    X = X.reshape(len(X), 1)\n",
    "    y = y.reshape(len(y), 1)\n",
    "    # define the model\n",
    "    model = GaussianProcessRegressor()\n",
    "    # fit the model\n",
    "    model.fit(X, y)\n",
    "    # plot before hand\n",
    "    plot(X, y, model)\n",
    "    # perform the optimization process\n",
    "    for i in range(100):\n",
    "        # select the next point to sample\n",
    "        x = opt_acquisition(X, y, model)\n",
    "        # sample the point\n",
    "        actual = objective(x)\n",
    "        # summarize the finding\n",
    "        est, _ = surrogate(model, [[x]])\n",
    "        print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "        # add the data to the dataset\n",
    "        X = vstack((X, [[x]]))\n",
    "        y = vstack((y, [[actual]]))\n",
    "        # update the model\n",
    "        model.fit(X, y)\n",
    "\n",
    "    # plot all samples and the final surrogate function\n",
    "    plot(X, y, model)\n",
    "    # best result\n",
    "    ix = argmax(y)\n",
    "    print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sobol sampling plus Nelder-Mead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulated anealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "# objective function\n",
    "class tstFxn:\n",
    "    def __init__(self):\n",
    "        self.X = np.linspace(0,1,1000)\n",
    "        self._y = np.asarray([self.objective(x) for x in self.X])\n",
    "        self.f =  interp1d(self.X, self._y,kind='cubic')\n",
    "        \n",
    "    def objective(self,x, noise=0.1):\n",
    "        noise = normal(loc=0, scale=noise)\n",
    "        return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#simulated anealing algorithm must have the following functions: \n",
    "# the feasable state space\n",
    "# the Energetic function (which is the objective function) E()\n",
    "# the candidate generator procedure (neighbor(x))\n",
    "#        -generation of random candidate vector, with variable magnitude?\n",
    "#         aniostropic exploration is better!!!\n",
    "#thoughts for how I might solve this problem - \n",
    "#         boundry check or only sampling within the boundry seems a good strategy. \n",
    "#        -moving in one direction at at time. \n",
    "\n",
    "# acceptance probability function P()\n",
    "# anealing schedule - number, number of anealing cycles, cooling rate\n",
    "# some termination condition - total execution time or number of interations\n",
    "# presensce of and number of restarts, deterministic or otherwise? \n",
    "\n",
    "#of these, cooling schedule and neighbor seem the most important functions\n",
    "\n",
    "\n",
    "class SA:\n",
    "    def __init__(self,boxConstraints):\n",
    "        self.nIter = 1000;\n",
    "        self.T = 1             #temperature variable on [1-0)\n",
    "        self.N = 1             #neighborhood size coefficient [1-0)\n",
    "        self.k = 1             #boltsman constant \n",
    "        self.C_half = 200      #half-life cooling              [trials]\n",
    "        self.N_half = 150      #half-life of neighborhood size [trials]\n",
    "        bcs = boxConstraints\n",
    "        self.lMax = bcs[0,:]   #upper limits on box constraints for x variable\n",
    "        self.lMin = bcs[1,:]   #lower limits on box constraints for x variable\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        sample the space for the next sample based on the neighborhood\n",
    "        function\n",
    "        input:\n",
    "            x\n",
    "        output:\n",
    "            x_new\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    def optimize(self,obj):\n",
    "        x0 = .5 ; fx0 = obj(x0)\n",
    "        for n in range(self.nIter):\n",
    "            x = np.random.random()\n",
    "            fx = obj(x)\n",
    "            \n",
    "            #if better, keep\n",
    "            if fx > fx0:\n",
    "                fx0 = fx ; x0 = x\n",
    "                \n",
    "            #probablastically accept worse answer\n",
    "            else:\n",
    "                Δf = fx - fx0\n",
    "                r = np.random.random()\n",
    "                if r > np.exp(-Δf/self.k*self.T):\n",
    "                    fx0 = fx ; x0 = x\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            #decrease temperature and neighborhood size\n",
    "            self.T = .5**(n/self.C_half)\n",
    "            self.N = .5**(n/self.N_half)\n",
    "        \n",
    "        return x0,fx0\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#if test:\n",
    "#     #plot\n",
    "#     tester = tstFxn()\n",
    "#     sa = SA()\n",
    "\n",
    "#     sa.optimize(tester.f)\n",
    "    \n",
    "#     %timeit sa.optimize(test.f)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
