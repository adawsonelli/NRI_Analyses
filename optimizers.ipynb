{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baysian optimization\n",
    "\n",
    "#### resources\n",
    "* https://gpflowopt.readthedocs.io/en/latest/notebooks/constrained_bo.html baysian optimization with constraints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of bayesian optimization for a 1d function from scratch\n",
    "from math import sin\n",
    "from math import pi\n",
    "from numpy import arange\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# objective function\n",
    "def objective(x, noise=0.1):\n",
    "    noise = normal(loc=0, scale=noise)\n",
    "    return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(X, return_std=True)\n",
    "\n",
    "# probability of improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "    # calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    mu = mu[:, 0]\n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "    return probs\n",
    "\n",
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, y, model):\n",
    "    # random search, generate random samples\n",
    "    Xsamples = random(100)\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = argmax(scores)\n",
    "    return Xsamples[ix, 0]\n",
    "\n",
    "# plot real observations vs surrogate function\n",
    "def plot(X, y, model):\n",
    "    # scatter plot of inputs and real objective function\n",
    "    pyplot.scatter(X, y)\n",
    "    # line plot of surrogate function across domain\n",
    "    Xsamples = asarray(arange(0, 1, 0.001))\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "    ysamples, _ = surrogate(model, Xsamples)\n",
    "    pyplot.plot(Xsamples, ysamples)\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "if test:\n",
    "    # sample the domain sparsely with noise\n",
    "    X = random(100)\n",
    "    y = asarray([objective(x) for x in X])\n",
    "    # reshape into rows and cols\n",
    "    X = X.reshape(len(X), 1)\n",
    "    y = y.reshape(len(y), 1)\n",
    "    # define the model\n",
    "    model = GaussianProcessRegressor()\n",
    "    # fit the model\n",
    "    model.fit(X, y)\n",
    "    # plot before hand\n",
    "    plot(X, y, model)\n",
    "    # perform the optimization process\n",
    "    for i in range(100):\n",
    "        # select the next point to sample\n",
    "        x = opt_acquisition(X, y, model)\n",
    "        # sample the point\n",
    "        actual = objective(x)\n",
    "        # summarize the finding\n",
    "        est, _ = surrogate(model, [[x]])\n",
    "        print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "        # add the data to the dataset\n",
    "        X = vstack((X, [[x]]))\n",
    "        y = vstack((y, [[actual]]))\n",
    "        # update the model\n",
    "        model.fit(X, y)\n",
    "\n",
    "    # plot all samples and the final surrogate function\n",
    "    plot(X, y, model)\n",
    "    # best result\n",
    "    ix = argmax(y)\n",
    "    print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sobol sampling plus Nelder-Mead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulated anealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "# objective function\n",
    "class tstFxn:\n",
    "    def __init__(self):\n",
    "        self.X = np.linspace(0,1,1000)\n",
    "        self._y = np.asarray([self.objective(x) for x in self.X])\n",
    "        self.f =  interp1d(self.X, self._y,kind='cubic')\n",
    "        \n",
    "    def objective(self,x, noise=0.1):\n",
    "        noise = normal(loc=0, scale=noise)\n",
    "        return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "\n",
    "\n",
    "class SA:\n",
    "    def __init__(self):\n",
    "        self.nIter = 1000;\n",
    "        self.T = 1000;\n",
    "        self.k = 1          #boltsman constant \n",
    "        self.c = .99        #cooling factor\n",
    "        \n",
    "        \n",
    "    def optimize(self,obj):\n",
    "        x0 = .5 ; fx0 = obj(x0)\n",
    "        for n in range(self.nIter):\n",
    "            x = np.random.random()\n",
    "            fx = obj(x)\n",
    "            \n",
    "            #if better, keep\n",
    "            if fx > fx0:\n",
    "                fx0 = fx ; x0 = x\n",
    "                \n",
    "            #probablastically accept worse answer\n",
    "            else:\n",
    "                Δf = fx - fx0\n",
    "                r = np.random.random()\n",
    "                if r > np.exp(-Δf/self.k*self.T):\n",
    "                    fx0 = fx ; x0 = x\n",
    "                else:\n",
    "                    pass\n",
    "            #decrease temperature\n",
    "            self.T = self.T * self.c\n",
    "        \n",
    "        return x0,fx0\n",
    "                    \n",
    " \n",
    "\n",
    "if test:\n",
    "    #plot\n",
    "    tester = tstFxn()\n",
    "    sa = SA()\n",
    "\n",
    "    sa.optimize(tester.f)\n",
    "    \n",
    "    %timeit sa.optimize(test.f)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
