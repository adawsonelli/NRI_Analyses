{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "\n",
    "This notebook serves as a library of optimizers, as well as a set of test functions that evaluate optimizer performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the notebook is being used as a library, or being run as a notebook\n",
    "asLibrary = lambda : '__file__' in globals()\n",
    "if asLibrary():\n",
    "    print(\"optimizers run as library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the the optimizer interface\n",
    "to maitain a level of decoupling between elements of the software system, the optimizer will not be given access to the robot or the experiment explicitly, but will deal instead only with function handles for the objective function and constraint functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimization interface here\n",
    "class Opt:\n",
    "    \"\"\"\n",
    "    defines the interface that all types of optimizer should follow\n",
    "    \"\"\"\n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \"\"\"\n",
    "        the function which actually performs the optimization or sampling\n",
    "        inputs:\n",
    "            obj - a function handle from exp.objective\n",
    "            bounds - an [2xn] np.array of box constraints\n",
    "            constraints - a list of function handles to hard constraint functions (to be implemented)\n",
    "        outputs:\n",
    "            x - a list of np.array objects, each of which is a solution\n",
    "                list of the parameter for the optimal solution\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: \n",
    "* write a BFGS class, and try to use it to solve for an optimal solution, within the specified bounds. \n",
    "\n",
    "\n",
    "\n",
    "* make binder work with jupyter lab, not just jupyter notebook\n",
    "* extend this to include solving the problem n times, from different sobol sampled locations. \n",
    "* view the solutions\n",
    "* work on sobol sampling + dispersion optimization.\n",
    "* if we have a good design, discuss what needs to be improved on the human end to make this an actually good model, including some of the other features you wanted. \n",
    "* start working on penalty functions, or on \n",
    "\n",
    "from future import:\n",
    "* might be nice at some point to develop a visualizer to visualize different trajectories on the robot with an animate button\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# objective function\n",
    "class testObjFxn:\n",
    "    def __init__(self):\n",
    "        self.X = np.linspace(0,1,1000)\n",
    "        self._y = np.asarray([self.objective(x) for x in self.X])\n",
    "        self.f =  interp1d(self.X, self._y,kind='cubic')\n",
    "        \n",
    "    def objective(self,x, noise=0.1):\n",
    "        noise = np.random.normal(loc=0, scale=noise)\n",
    "        return (x**2 * np.sin(5 * np.pi * x)**6.0) + noise\n",
    "    \n",
    "    def pltSampleHistory(self,x,fx):\n",
    "        n = len(x)\n",
    "        \n",
    "        #x vs. f(x)\n",
    "        fig = go.Figure()\n",
    "        fig.add_scatter(mode=\"markers\", marker = dict(color = np.linspace(0,1,n)),name=\"Sample\")\n",
    "        fig.data[0]['x'] = x\n",
    "        fig.data[0]['y'] = fx\n",
    "        display(fig)\n",
    "        \n",
    "        \n",
    "        #n vs fx\n",
    "        fig2 = go.Figure()\n",
    "        fig2.add_scatter(x=np.arange(0,n,1),y=fx,name=\"Sample\")\n",
    "        display(fig2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baysian optimization\n",
    "\n",
    "#### resources\n",
    "* https://gpflowopt.readthedocs.io/en/latest/notebooks/constrained_bo.html baysian optimization with constraints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example of bayesian optimization for a 1d function from scratch\n",
    "# from math import sin\n",
    "# from math import pi\n",
    "# from numpy import arange\n",
    "# from numpy import vstack\n",
    "# from numpy import argmax\n",
    "# from numpy import asarray\n",
    "# from numpy.random import normal\n",
    "# from numpy.random import random\n",
    "# from scipy.stats import norm\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from warnings import catch_warnings\n",
    "# from warnings import simplefilter\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# # objective function\n",
    "# def objective(x, noise=0.1):\n",
    "#     noise = normal(loc=0, scale=noise)\n",
    "#     return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "# # surrogate or approximation for the objective function\n",
    "# def surrogate(model, X):\n",
    "#     # catch any warning generated when making a prediction\n",
    "#     with catch_warnings():\n",
    "#         # ignore generated warnings\n",
    "#         simplefilter(\"ignore\")\n",
    "#         return model.predict(X, return_std=True)\n",
    "\n",
    "# # probability of improvement acquisition function\n",
    "# def acquisition(X, Xsamples, model):\n",
    "#     # calculate the best surrogate score found so far\n",
    "#     yhat, _ = surrogate(model, X)\n",
    "#     best = max(yhat)\n",
    "#     # calculate mean and stdev via surrogate function\n",
    "#     mu, std = surrogate(model, Xsamples)\n",
    "#     mu = mu[:, 0]\n",
    "#     # calculate the probability of improvement\n",
    "#     probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "#     return probs\n",
    "\n",
    "# # optimize the acquisition function\n",
    "# def opt_acquisition(X, y, model):\n",
    "#     # random search, generate random samples\n",
    "#     Xsamples = random(100)\n",
    "#     Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "#     # calculate the acquisition function for each sample\n",
    "#     scores = acquisition(X, Xsamples, model)\n",
    "#     # locate the index of the largest scores\n",
    "#     ix = argmax(scores)\n",
    "#     return Xsamples[ix, 0]\n",
    "\n",
    "# # plot real observations vs surrogate function\n",
    "# def plot(X, y, model):\n",
    "#     # scatter plot of inputs and real objective function\n",
    "#     pyplot.scatter(X, y)\n",
    "#     # line plot of surrogate function across domain\n",
    "#     Xsamples = asarray(arange(0, 1, 0.001))\n",
    "#     Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "#     ysamples, _ = surrogate(model, Xsamples)\n",
    "#     pyplot.plot(Xsamples, ysamples)\n",
    "#     # show the plot\n",
    "#     pyplot.show()\n",
    "    \n",
    "\n",
    "# if not asLibrary():\n",
    "#     # sample the domain sparsely with noise\n",
    "#     X = random(100)\n",
    "#     y = asarray([objective(x) for x in X])\n",
    "#     # reshape into rows and cols\n",
    "#     X = X.reshape(len(X), 1)\n",
    "#     y = y.reshape(len(y), 1)\n",
    "#     # define the model\n",
    "#     model = GaussianProcessRegressor()\n",
    "#     # fit the model\n",
    "#     model.fit(X, y)\n",
    "#     # plot before hand\n",
    "#     plot(X, y, model)\n",
    "#     # perform the optimization process\n",
    "#     for i in range(100):\n",
    "#         # select the next point to sample\n",
    "#         x = opt_acquisition(X, y, model)\n",
    "#         # sample the point\n",
    "#         actual = objective(x)\n",
    "#         # summarize the finding\n",
    "#         est, _ = surrogate(model, [[x]])\n",
    "#         print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "#         # add the data to the dataset\n",
    "#         X = vstack((X, [[x]]))\n",
    "#         y = vstack((y, [[actual]]))\n",
    "#         # update the model\n",
    "#         model.fit(X, y)\n",
    "\n",
    "#     # plot all samples and the final surrogate function\n",
    "#     plot(X, y, model)\n",
    "#     # best result\n",
    "#     ix = argmax(y)\n",
    "#     print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sobol sampling\n",
    "\n",
    "the idea behind this approach is to evaluate:\n",
    "1. if the function we are dealing with is convex, (in which case, all of the simplex methods will end up at the same place)\n",
    "2. if it's not convex, are there local solutions that are interesting to consider (perhaps are less sensitive, or better in some way we didn't anticipate?) the idea would be to visually inspect these solutions for their quality.\n",
    "\n",
    "\n",
    "#### refs:\n",
    "https://people.sc.fsu.edu/~jburkardt/py_src/sobol/sobol.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73d22073ad844fcabd6272c6f70e8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='samps', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca7e2171abe422d9c9802aec85ec472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.      , 0.001001, 0.002002, ..., 0.997998, 0.998999,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sobol import i4_sobol\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "class Sobol:\n",
    "    \"\"\"\n",
    "    the sobol opt class \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.n = 1000          #number of samples to evaluate\n",
    "        self.nBest = 10        #number to keep\n",
    "        self.xBest = []        #list of nBest x values\n",
    "        self.fxBest = []       #list of nBest obj function values\n",
    "        self.randomSeed = True #should sample seed be randomized?\n",
    "        \n",
    "        self.selectionFxn = \"max_fx\" #str name of selection fxn [\"max_fx\", \"obj_var_tradeoff\"]\n",
    "        self.W_obj = 1                #importance parameter for objective fxn\n",
    "        self.W_dispersion = 1         #importance parameter for dispersion metric \n",
    "        \n",
    "        self.xs = []                  #n x's\n",
    "        self.fxs = []                 #n solutions\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def twoPointLine(x,x1,y1,x2,y2):\n",
    "        \"\"\"returns y given the formula of a line specified in 2 point form\"\"\"\n",
    "        return ((y2-y1)/(x2-x1))*(x - x1) + y1\n",
    "    \n",
    "    @staticmethod\n",
    "    def Sample(bounds,n,randomSeed = True):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "            bounds - [nx2] array of [max,min]\n",
    "            n - number of sample points requested\n",
    "            randomSeed - bool - start in a place other than 0\n",
    "        outputs:\n",
    "            samps - list of np.arrays  (so you can interate through them more easily)\n",
    "        \"\"\"\n",
    "        #calc the sobol inputs\n",
    "        ndims = bounds.shape[0]\n",
    "        upperbounds = bounds[:,0] ; lowerbounds = bounds[:,1]\n",
    "        if randomSeed: seed_0 = np.random.randint(0,10000)\n",
    "        else: seed_0 = 0\n",
    "        \n",
    "        #sample the unit hypercube\n",
    "        samps = [i4_sobol(ndims, seed)[0] for seed in range(seed_0,n + seed_0)]\n",
    "        #samps = np.array(samps)\n",
    "        \n",
    "        #shift and scale from the unit hypercube to the bounds rectangular prism\n",
    "        sl = []  #samps list\n",
    "        for sample in samps:\n",
    "            sn = np.zeros(ndims)  #sample new\n",
    "            for i,x in enumerate(sample):\n",
    "                x1 = 0 ; x2 = 1\n",
    "                y1 = lowerbounds[i] ; y2 = upperbounds[i]\n",
    "                sn[i] = Sobol.twoPointLine(x,x1,y1,x2,y2)\n",
    "            sl.append(sn)\n",
    "        \n",
    "        return sl\n",
    "    \n",
    "    \n",
    "    #------------------ selection fxns ------------------------\n",
    "    def max_fx(self):\n",
    "        \"\"\"\n",
    "        return the nBest results based only on the value of Fx\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def re_sample(self):\n",
    "        pass\n",
    "    \n",
    "    def histSelect(self):\n",
    "        \"\"\"\n",
    "        randomly select solutions from the top percent,and place them in the xBest\n",
    "        and fxBest\n",
    "        \"\"\"\n",
    "        nbest = 10\n",
    "        ids = np.argsort(self.fxs)[::-1][:nbest]\n",
    "        \n",
    "        #place best solutions into list\n",
    "        self.xBest  = [self.xs[i]  for i in ids]\n",
    "        self.fxBest = [self.fxs[i] for i in ids]\n",
    "    \n",
    "    #------------------- optimization --------------------------\n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \"\"\"\n",
    "       discover interesting and good solutions at different locations within the space, \n",
    "       no optimization is performed strictly speaking, just structured exploration\n",
    "        \"\"\"\n",
    "        self.xs = Sobol.Sample(bounds,self.n,self.randomSeed)\n",
    "        self.fxs = [] \n",
    "        for x in self.xs:\n",
    "            self.fxs.append(obj(x))\n",
    "        \n",
    "        return eval('self.' + self.selectionFxn + '()')\n",
    "\n",
    "\n",
    "class SobolVis:\n",
    "    \"\"\"\n",
    "    just want to get a sense for what sampling a unit space\n",
    "    using sobol sampling looks like\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        _fig = go.Figure(data=[go.Scatter3d(z=[0],x=[0],y=[0], name = \"sampling\",mode=\"markers\",\n",
    "                                            marker = dict(size=10,color = np.linspace(0,1,1000),showscale=True))])\n",
    "        self.fig = go.FigureWidget(_fig)\n",
    "        n = widgets.IntSlider(min=1,max=1000,value=1,description='samps')\n",
    "        self.wdict = {\"n\":n}\n",
    "        \n",
    "        self.fig.update_layout(\n",
    "            autosize=False,\n",
    "            width = 800,\n",
    "            height= 800,\n",
    "            legend=dict(x=.025, y=.975),\n",
    "            margin=dict(l=0, r=20, t=0, b=0))\n",
    "        \n",
    "    def genSamps(self,n):\n",
    "        #how to use sobol\n",
    "        bounds = np.array([[.5,1,-1],[.25,-1,-3]]).T\n",
    "        samps = Sobol.Sample(bounds,n,randomSeed = False)\n",
    "        #samps = [i4_sobol(dim_num, seed)[0] for seed in range(n)]\n",
    "        samps = np.array(samps)\n",
    "        xs = samps[:,0] ; ys = samps[:,1] ; zs = samps[:,2]\n",
    "        return xs,ys,zs\n",
    "    \n",
    "    \n",
    "    def update(self,n=1):\n",
    "        fig = self.fig\n",
    "        with fig.batch_update():\n",
    "            #plot n sobol points, with coloring\n",
    "            xs,ys,zs = self.genSamps(n)\n",
    "            \n",
    "            fig.data[0]['x']= xs\n",
    "            fig.data[0]['y']= ys\n",
    "            fig.data[0]['z']= zs\n",
    "            \n",
    "            \n",
    "    def disp(self):\n",
    "        self.out = widgets.interactive_output(self.update, self.wdict)\n",
    "        display(self.wdict[\"n\"])\n",
    "        display(self.fig)\n",
    "        \n",
    "\n",
    "#interactive 3D sobol sampling visualization to get a sense of the algorithm \n",
    "if not asLibrary() and True:\n",
    "    vis = SobolVis()\n",
    "    vis.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "b = np.array((1,2,3))\n",
    "b[[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS \n",
    "Broyden–Fletcher–Goldfarb–Shanno (BFGS) is a quazi-newton optimization method that uses the secant approach to find stationary points via locating the zeros of the gradient (jacobian) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "class BFGS:\n",
    "    def __init__(self):\n",
    "        self.mode = \"seeded\"   #[\"seeded\",\"sobol\",\"SA\"] \n",
    "        self.n = 1             #number of starting points\n",
    "        self.x0 = []           #incase you want to prime the algorithm, from outside manipulation\n",
    "        self.xBest = []        #list of n x values\n",
    "        self.fxBest = []       #list of n obj function values\n",
    "        self.res = []          #results of most recent optimization\n",
    "        \n",
    "    def optimize(self,obj,bounds,constraints): #refactor to remove this code repetition.\n",
    "        \n",
    "        #specify the bounds:\n",
    "        bnds = Bounds(bounds[:,1],bounds[:,0],keep_feasible=True)\n",
    "        \n",
    "        #specify the fixed step size (epsilon):\n",
    "        eps = (bounds[:,0] - bounds[:,1])/10000\n",
    "        \n",
    "        #make a maximum into a minimum\n",
    "        min_obj = lambda x: -1 * obj(x)\n",
    "        \n",
    "        if self.mode == \"seeded\":\n",
    "            self.res = minimize(min_obj,\n",
    "                                self.x0[0],\n",
    "                                method='BFGS',\n",
    "                                jac = False,\n",
    "                                bounds = bnds,\n",
    "                                options={'gtol': 1e-3,\n",
    "                                         'disp': True,\n",
    "                                         'eps': eps})\n",
    "                                        #'finite_diff_rel_step':finite_diff_rel_step})\n",
    "            self.xBest.append(self.res.x)\n",
    "            self.fxBest.append(1)\n",
    "            \n",
    "        elif self.mode == \"sobol\":\n",
    "            samps = Sobol.Sample(bounds,self.n,randomSeed = True)\n",
    "            for x0 in samps:\n",
    "                self.res = minimize(obj, x0, method='BFGS',\n",
    "                           options={'gtol': 1e-6, 'disp': True})\n",
    "                self.xBest.append(self.res.x)\n",
    "                self.fxBest.append(1)\n",
    "        \n",
    "        return self.xBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "optimize() missing 2 required positional arguments: 'bounds' and 'constraints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-f986983710da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetBounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxConstraints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtester\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxBest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: optimize() missing 2 required positional arguments: 'bounds' and 'constraints'"
     ]
    }
   ],
   "source": [
    "#simulated anealing algorithm must have the following functions: \n",
    "# the feasable state space\n",
    "# the Energetic function (which is the objective function) E()\n",
    "# the candidate generator procedure (neighbor(x))\n",
    "#        -generation of random candidate vector, with variable magnitude?\n",
    "#         aniostropic exploration is better!!!\n",
    "#thoughts for how I might solve this problem - \n",
    "#         boundry check or only sampling within the boundry seems a good strategy. \n",
    "#        -moving in one direction at at time. \n",
    "\n",
    "# acceptance probability function P()\n",
    "# anealing schedule - number, number of anealing cycles, cooling rate\n",
    "# some termination condition - total execution time or number of interations\n",
    "# presensce of and number of restarts, deterministic or otherwise? \n",
    "\n",
    "#of these, cooling schedule and neighbor seem the most important functions\n",
    "\n",
    "\n",
    "class SA:\n",
    "    def __init__(self):\n",
    "        self.nIter = 1000;                     #total number of iterations to perform\n",
    "        self.nResets = 3                       #number of resets to best \n",
    "        self.brt = self._brt()                 #trial numbers during which to reset to best\n",
    "        self.dist = \"uniform\"                  #neighborhood sampling method \n",
    "        self.aMode = \"exp\"                     #Annealing mode [\"exp\",\"linear\",\"stepped\"]\n",
    "        self.nMode = \"linear\"                  #neighborhood Mode\n",
    "        self.T = 1                             #temperature variable on [1-0)\n",
    "        self.N = 1                             #neighborhood size coefficient [1-0)\n",
    "        self.C_half = 200                      #half-life cooling              [trials]\n",
    "        self.N_half = 150                      #half-life of neighborhood size [trials]\n",
    "        self.fxBest = 0                        #best encountered function value\n",
    "        self.xBest = []                        #location of best value\n",
    "        self.dbg = False                        #save variables for debugging\n",
    "        self.xCache  = []                      #storage for x\n",
    "        self.FxCache = []                      #storage for Fx\n",
    "        self.updateReports = True              #should we print out an update of how the optimization is progressing?\n",
    "        self.updateCount = 10                  #number of updates\n",
    "        \n",
    "        \n",
    "    def setBounds(self,bcs):\n",
    "        self.x_max = bcs[:,0]                  #upper limits on box constraints for x variable\n",
    "        self.x_min = bcs[:,1]                  #lower limits on box constraints for x variable\n",
    "        \n",
    "    def _center(self,x_max,x_min):\n",
    "        \"\"\"\n",
    "        find  the center of a box defined by limits\n",
    "        \"\"\"\n",
    "        return [(x_max[i] + x_min[i])/2 for i in range(len(x_max))]\n",
    "    \n",
    "    def _twoPointLine(self,x,x1,y1,x2,y2):\n",
    "        \"\"\"\n",
    "        returns y given the formula of a line specified in 2 point form\n",
    "        \"\"\"\n",
    "        return ((y2-y1)/(x2-x1))*(x - x1) + y1\n",
    "    \n",
    "    def _brt(self):\n",
    "        \"\"\"\n",
    "        calculate the best reset trials, evenly distribute in n_iter\n",
    "        \"\"\"\n",
    "        return np.random.randint(low  = int(self.nIter/5),\n",
    "                                 high = self.nIter,\n",
    "                                 size = self.nResets)\n",
    "        \n",
    "            \n",
    "    def sample(self,x):\n",
    "        \"\"\"\n",
    "        sample the space for the next sample based on the neighborhood\n",
    "        function\n",
    "        input:\n",
    "            x\n",
    "        output:\n",
    "            x_new\n",
    "        \"\"\"\n",
    "        #define the (ever-shrinking) neighborhood bounding box\n",
    "        w = self.N * ((self.x_max - self.x_min)/2) \n",
    "        nx_max = x + w\n",
    "        nx_min = x - w\n",
    "        \n",
    "        #define the combined bounding box as an intersection between\n",
    "        #the box constraints and the neighborhood box - a mini-max problem\n",
    "        cx_max = np.amin(np.vstack((self.x_max,nx_max)),axis = 0)\n",
    "        cx_min =  np.max(np.vstack((self.x_min,nx_min)),axis = 0)\n",
    "        \n",
    "#         for i in range(len(self.x_max)):\n",
    "#             cx_max[i] = min(self.x_max,nx_max[i])\n",
    "#             cx_min[i] = max(self.x_min,nx_min[i])\n",
    "        \n",
    "        #sample from the combined box, according to the appropriate distribution\n",
    "        if self.dist == \"uniform\": \n",
    "            x_new = np.random.uniform(cx_min,cx_max) #vectorized\n",
    "            \n",
    "        if self.dist == \"normal\":\n",
    "            pass\n",
    "#             zScore = 1.645 #95% confidence interval\n",
    "#             x_new = []\n",
    "#             while len(x_new) > len(self.x_min):\n",
    "#                 x = np.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "#                 if abs(x) < zScore:\n",
    "#                     x_new.append(x)\n",
    "#             c_range = cx_max - cx_min\n",
    "            \n",
    " \n",
    "        return x_new\n",
    "\n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \n",
    "        #set box constraints\n",
    "        bcs = bounds()\n",
    "        self.setBounds(bcs)\n",
    "        \n",
    "        #init x0 and fx0\n",
    "        x0 =  self._center(self.x_max,self.x_min)\n",
    "        fx0 = obj(x0)\n",
    "        \n",
    "        for n in range(self.nIter + 1):\n",
    "            x = self.sample(x0)\n",
    "            fx = obj(x)\n",
    "            \n",
    "            #if better, always keep\n",
    "            if fx > fx0:\n",
    "                x0 = x ; fx0 = fx\n",
    "                \n",
    "            #probabalistically accept worse answer\n",
    "            else:\n",
    "                Δf = fx - fx0\n",
    "                r = np.random.random()\n",
    "                if r < np.exp(Δf/self.T):\n",
    "                    fx0 = fx ; x0 = x\n",
    "                    #print(x)\n",
    "                else:\n",
    "                    pass\n",
    "             \n",
    "            \n",
    "            #maintain best (for restarts, if used)\n",
    "            if fx > self.fxBest:\n",
    "                self.xBest = x  ; self.fxBest = fx \n",
    "                \n",
    "            #do a best restart:\n",
    "            if n in self.brt:\n",
    "                  x0 = self.xBest ; fx0 = self.fxBest \n",
    "            \n",
    "            #decrease temperature and neighborhood size\n",
    "            if self.aMode == \"exp\": self.T = .5**(n/self.C_half)\n",
    "            if self.nMode == \"exp\": self.N = .5**(n/self.N_half)\n",
    "            \n",
    "            if self.aMode == \"Linear\": self.T = self._twoPointLine(n,0,1,self.nIter,0)\n",
    "            if self.nMode == \"Linear\": self.N = self._twoPointLine(n,0,1,self.nIter,0)\n",
    "                \n",
    "                  \n",
    "            #store debugging vars\n",
    "            if self.dbg:\n",
    "                self.xCache.append(x0[0])\n",
    "                self.FxCache.append(fx0[0])\n",
    "                \n",
    "            #give updates\n",
    "            if self.updateReports:\n",
    "                if n % ((self.nIter) / 10) == 0:\n",
    "                    print(\"on iteration %d\" %n)\n",
    "        \n",
    "        return x0\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if not asLibrary():\n",
    "#     #plot\n",
    "#     tester = testObjFxn()\n",
    "#     boxConstraints = np.array([[1,0]])\n",
    "#     sa = SA()\n",
    "#     sa.dbg = True\n",
    "#     sa.setBounds(boxConstraints)\n",
    "\n",
    "#     x0,fx0 = sa.optimize(tester.f)\n",
    "#     print(x0,fx0)\n",
    "#     print(sa.xBest)\n",
    "    \n",
    "#     tester.pltSampleHistory(sa.xCache,sa.FxCache)\n",
    "    \n",
    "#     #%timeit sa.optimize(tester.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the DIRECT Algorithm\n",
    "the direct algorithm is a global optimization method that breaks up a bounded hyper-rectangle search space into progressively smaller and smaller sub-rectangles by identifity (via checking the center point of the rectangle) which areas of the input space are most prominsing. \n",
    "\n",
    "note, that the pre-reqs for this suck, so we won't support it online (nor will we likely support any online optimization)\n",
    "\n",
    "https://github.com/andim/scipydirect/blob/master/doc/install.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipydirect import minimize\n",
    "\n",
    "\n",
    "def obj(x):\n",
    "    \"\"\"Six-hump camelback function\"\"\"\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    f = (4 - 2.1*(x1*x1) + (x1*x1*x1*x1)/3.0)*(x1*x1) + x1*x2 + (-4 + 4*(x2*x2))*(x2*x2)\n",
    "    return f\n",
    "\n",
    "\n",
    "bounds = [(-3, 3), (-2, 2)]\n",
    "\n",
    "#res = minimize(obj, bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-07edc18fae97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\programFiles\\Miniconda3\\envs\\NRI\\lib\\site-packages\\scipydirect\\__init__.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(func, bounds, nvar, args, disp, eps, maxf, maxT, algmethod, fglobal, fglper, volper, sigmaper, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;31m# Call the DIRECT algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     x, fun, ierror = direct(\n\u001b[0m\u001b[0;32m    239\u001b[0m                         \u001b[0m_objective_wrap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "minimize(obj,bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bd213e631f34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programFiles\\Miniconda3\\envs\\NRI\\lib\\site-packages\\scipydirect\\__init__.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(func, bounds, nvar, args, disp, eps, maxf, maxT, algmethod, fglobal, fglper, volper, sigmaper, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;31m# Call the DIRECT algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     x, fun, ierror = direct(\n\u001b[0m\u001b[0;32m    239\u001b[0m                         \u001b[0m_objective_wrap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "def obj(x):\n",
    "    return (x**2).sum()\n",
    "\n",
    "bounds = [[-3.0, 3.0], [0.5, 5.0]]\n",
    "res = minimize(obj, bounds=bounds)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package cma:\n",
      "\n",
      "NAME\n",
      "    cma\n",
      "\n",
      "DESCRIPTION\n",
      "    Package `cma` implements the CMA-ES (Covariance Matrix Adaptation\n",
      "    Evolution Strategy).\n",
      "    \n",
      "    CMA-ES is a stochastic optimizer for robust non-linear non-convex\n",
      "    derivative- and function-value-free numerical optimization.\n",
      "    \n",
      "    This implementation can be used with Python versions >= 2.7, namely,\n",
      "    it was tested with 2.7, 3.5, 3.6, 3.7, 3.8.\n",
      "    \n",
      "    CMA-ES searches for a minimizer (a solution x in :math:`R^n`) of an\n",
      "    objective function f (cost function), such that f(x) is minimal.\n",
      "    Regarding f, only a passably reliable ranking of the candidate\n",
      "    solutions in each iteration is necessary. Neither the function values\n",
      "    itself, nor the gradient of f need to be available or do matter (like\n",
      "    in the downhill simplex Nelder-Mead algorithm). Some termination\n",
      "    criteria however depend on actual f-values.\n",
      "    \n",
      "    The `cma` module provides two independent implementations of the\n",
      "    CMA-ES algorithm in the classes `cma.CMAEvolutionStrategy` and\n",
      "    `cma.purecma.CMAES`.\n",
      "    \n",
      "    In each implementation two interfaces are provided:\n",
      "    \n",
      "    - functions `fmin` and `purecma.fmin`:\n",
      "        run a complete minimization of the passed objective function with\n",
      "        CMA-ES. `fmin` also provides optional restarts and noise handling.\n",
      "    \n",
      "    - class `CMAEvolutionStrategy` and `purecma.CMAES`:\n",
      "        allow for minimization such that the control of the iteration\n",
      "        loop remains with the user.\n",
      "    \n",
      "    The `cma` package root provides shortcuts to these and other classes and\n",
      "    functions.\n",
      "    \n",
      "    Used external packages are `numpy` (only `purecma` does not depend on\n",
      "    `numpy`) and `matplotlib.pyplot` (for `plot` etc., optional but highly\n",
      "    recommended).\n",
      "    \n",
      "    Install\n",
      "    =======\n",
      "    To use the module, the folder ``cma`` only needs to be visible in the\n",
      "    python path, e.g. in the current working directory.\n",
      "    \n",
      "    To install the module from pipy, type::\n",
      "    \n",
      "        pip install cma\n",
      "    \n",
      "    from the command line.\n",
      "    \n",
      "    To install the module from a ``cma`` folder::\n",
      "    \n",
      "        pip install -e cma\n",
      "    \n",
      "    To upgrade the currently installed version use additionally the ``-U``\n",
      "    option.\n",
      "    \n",
      "    Testing\n",
      "    =======\n",
      "    From the system shell::\n",
      "    \n",
      "        python -m cma.test -h\n",
      "        python -m cma.test\n",
      "        python -c \"import cma.test; cma.test.main()\"  # the same\n",
      "    \n",
      "    or from any (i)python shell::\n",
      "    \n",
      "        import cma.test\n",
      "        cma.test.main()\n",
      "    \n",
      "    should run without complaints in about between 20 and 100 seconds.\n",
      "    \n",
      "    Example\n",
      "    =======\n",
      "    From a python shell::\n",
      "    \n",
      "        import cma\n",
      "        help(cma)  # \"this\" help message, use cma? in ipython\n",
      "        help(cma.fmin)\n",
      "        help(cma.CMAEvolutionStrategy)\n",
      "        help(cma.CMAOptions)\n",
      "        cma.CMAOptions('tol')  # display 'tolerance' termination options\n",
      "        cma.CMAOptions('verb') # display verbosity options\n",
      "        res = cma.fmin(cma.ff.tablet, 15 * [1], 1)\n",
      "        es = cma.CMAEvolutionStrategy(15 * [1], 1).optimize(cma.ff.tablet)\n",
      "        help(es.result)\n",
      "        res[0], es.result[0]  # best evaluated solution\n",
      "        res[5], es.result[5]  # mean solution, presumably better with noise\n",
      "    \n",
      "    :See also: `fmin` (), `CMAOptions`, `CMAEvolutionStrategy`\n",
      "    \n",
      "    :Author: Nikolaus Hansen, 2008-\n",
      "    :Author: Petr Baudis, 2014\n",
      "    :Author: Youhei Akimoto, 2017-\n",
      "    \n",
      "    :License: BSD 3-Clause, see LICENSE file.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    bbobbenchmarks\n",
      "    constraints_handler\n",
      "    evolution_strategy\n",
      "    fitness_functions\n",
      "    fitness_models\n",
      "    fitness_transformations\n",
      "    interfaces\n",
      "    logger\n",
      "    optimization_tools\n",
      "    purecma\n",
      "    recombination_weights\n",
      "    restricted_gaussian_sampler\n",
      "    s\n",
      "    sampler\n",
      "    sigma_adaptation\n",
      "    test\n",
      "    transformations\n",
      "    utilities (package)\n",
      "    wrapper\n",
      "\n",
      "DATA\n",
      "    ___author__ = 'Nikolaus Hansen and Petr Baudis and Youhei Akimoto'\n",
      "    __license__ = 'BSD 3-clause'\n",
      "    ff = <cma.fitness_functions.FitnessFunctions object>\n",
      "    test = 'type \"import cma.test\" to access the `test` module of `cma`'\n",
      "\n",
      "VERSION\n",
      "    3.0.3  $Revision: 4430 $ $Date: 2020-04-21 01:19:04 +0200 (Tue, 21 Apr 2020) $\n",
      "\n",
      "FILE\n",
      "    d:\\programfiles\\miniconda3\\envs\\nri\\lib\\site-packages\\cma\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cma\n",
    "help(cma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (0,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-572639ea831e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mxopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\programFiles\\Miniconda3\\envs\\NRI\\lib\\site-packages\\nlopt\\nlopt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nlopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt_optimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlast_optimize_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-572639ea831e>\u001b[0m in \u001b[0;36mobj\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (0,) "
     ]
    }
   ],
   "source": [
    "def obj(x1,x2):\n",
    "    return (x1**2 + x2**2).sum()\n",
    "\n",
    "lb = [-3.0, 3.0]\n",
    "ub = [0.5 , 5.0]\n",
    "\n",
    "\n",
    "import nlopt\n",
    "opt = nlopt.opt(nlopt.GN_DIRECT,2)\n",
    "opt.get_algorithm_name()\n",
    "\n",
    "opt.set_min_objective(obj)\n",
    "opt.set_lower_bounds(lb)\n",
    "opt.set_upper_bounds(ub)\n",
    "\n",
    "x = [0,4]\n",
    "xopt = opt.optimize(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
