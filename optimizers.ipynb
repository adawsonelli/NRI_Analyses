{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "\n",
    "This notebook serves as a library of optimizers, as well as a set of test functions that evaluate optimizer performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the notebook is being used as a library, or being run as a notebook\n",
    "asLibrary = lambda : '__file__' in globals()\n",
    "if asLibrary():\n",
    "    print(\"optimizers run as library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the the optimizer interface\n",
    "to maitain a level of decoupling between elements of the software system, the optimizer will not be given access to the robot or the experiment explicitly, but will deal instead only with function handles for the objective function and constraint functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimization interface here\n",
    "class Opt:\n",
    "    \"\"\"\n",
    "    defines the interface that all types of optimizer should follow\n",
    "    \"\"\"\n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \"\"\"\n",
    "        the function which actually performs the optimization or sampling\n",
    "        inputs:\n",
    "            obj - a function handle from exp.objective\n",
    "            bounds - an [2xn] np.array of box constraints\n",
    "            constraints - a list of function handles to hard constraint functions (to be implemented)\n",
    "        outputs:\n",
    "            x - a list of np.array objects, each of which is a solution\n",
    "                list of the parameter for the optimal solution\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: \n",
    "* write a BFGS class, and try to use it to solve for an optimal solution, within the specified bounds. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* extend this to include solving the problem n times, from different sobol sampled locations. \n",
    "* view the solutions\n",
    "* work on sobol sampling + dispersion optimization.\n",
    "* if we have a good design, discuss what needs to be improved on the human end to make this an actually good model, including some of the other features you wanted. \n",
    "* start working on penalty functions, or on \n",
    "\n",
    "from future import:\n",
    "* might be nice at some point to develop a visualizer to visualize different trajectories on the robot with an animate button\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# objective function\n",
    "class testObjFxn:\n",
    "    def __init__(self):\n",
    "        self.X = np.linspace(0,1,1000)\n",
    "        self._y = np.asarray([self.objective(x) for x in self.X])\n",
    "        self.f =  interp1d(self.X, self._y,kind='cubic')\n",
    "        \n",
    "    def objective(self,x, noise=0.1):\n",
    "        noise = np.random.normal(loc=0, scale=noise)\n",
    "        return (x**2 * np.sin(5 * np.pi * x)**6.0) + noise\n",
    "    \n",
    "    def pltSampleHistory(self,x,fx):\n",
    "        n = len(x)\n",
    "        \n",
    "        #x vs. f(x)\n",
    "        fig = go.Figure()\n",
    "        fig.add_scatter(mode=\"markers\", marker = dict(color = np.linspace(0,1,n)),name=\"Sample\")\n",
    "        fig.data[0]['x'] = x\n",
    "        fig.data[0]['y'] = fx\n",
    "        display(fig)\n",
    "        \n",
    "        \n",
    "        #n vs fx\n",
    "        fig2 = go.Figure()\n",
    "        fig2.add_scatter(x=np.arange(0,n,1),y=fx,name=\"Sample\")\n",
    "        display(fig2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baysian optimization\n",
    "\n",
    "#### resources\n",
    "* https://gpflowopt.readthedocs.io/en/latest/notebooks/constrained_bo.html baysian optimization with constraints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example of bayesian optimization for a 1d function from scratch\n",
    "# from math import sin\n",
    "# from math import pi\n",
    "# from numpy import arange\n",
    "# from numpy import vstack\n",
    "# from numpy import argmax\n",
    "# from numpy import asarray\n",
    "# from numpy.random import normal\n",
    "# from numpy.random import random\n",
    "# from scipy.stats import norm\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from warnings import catch_warnings\n",
    "# from warnings import simplefilter\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# # objective function\n",
    "# def objective(x, noise=0.1):\n",
    "#     noise = normal(loc=0, scale=noise)\n",
    "#     return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "# # surrogate or approximation for the objective function\n",
    "# def surrogate(model, X):\n",
    "#     # catch any warning generated when making a prediction\n",
    "#     with catch_warnings():\n",
    "#         # ignore generated warnings\n",
    "#         simplefilter(\"ignore\")\n",
    "#         return model.predict(X, return_std=True)\n",
    "\n",
    "# # probability of improvement acquisition function\n",
    "# def acquisition(X, Xsamples, model):\n",
    "#     # calculate the best surrogate score found so far\n",
    "#     yhat, _ = surrogate(model, X)\n",
    "#     best = max(yhat)\n",
    "#     # calculate mean and stdev via surrogate function\n",
    "#     mu, std = surrogate(model, Xsamples)\n",
    "#     mu = mu[:, 0]\n",
    "#     # calculate the probability of improvement\n",
    "#     probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "#     return probs\n",
    "\n",
    "# # optimize the acquisition function\n",
    "# def opt_acquisition(X, y, model):\n",
    "#     # random search, generate random samples\n",
    "#     Xsamples = random(100)\n",
    "#     Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "#     # calculate the acquisition function for each sample\n",
    "#     scores = acquisition(X, Xsamples, model)\n",
    "#     # locate the index of the largest scores\n",
    "#     ix = argmax(scores)\n",
    "#     return Xsamples[ix, 0]\n",
    "\n",
    "# # plot real observations vs surrogate function\n",
    "# def plot(X, y, model):\n",
    "#     # scatter plot of inputs and real objective function\n",
    "#     pyplot.scatter(X, y)\n",
    "#     # line plot of surrogate function across domain\n",
    "#     Xsamples = asarray(arange(0, 1, 0.001))\n",
    "#     Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "#     ysamples, _ = surrogate(model, Xsamples)\n",
    "#     pyplot.plot(Xsamples, ysamples)\n",
    "#     # show the plot\n",
    "#     pyplot.show()\n",
    "    \n",
    "\n",
    "# if not asLibrary():\n",
    "#     # sample the domain sparsely with noise\n",
    "#     X = random(100)\n",
    "#     y = asarray([objective(x) for x in X])\n",
    "#     # reshape into rows and cols\n",
    "#     X = X.reshape(len(X), 1)\n",
    "#     y = y.reshape(len(y), 1)\n",
    "#     # define the model\n",
    "#     model = GaussianProcessRegressor()\n",
    "#     # fit the model\n",
    "#     model.fit(X, y)\n",
    "#     # plot before hand\n",
    "#     plot(X, y, model)\n",
    "#     # perform the optimization process\n",
    "#     for i in range(100):\n",
    "#         # select the next point to sample\n",
    "#         x = opt_acquisition(X, y, model)\n",
    "#         # sample the point\n",
    "#         actual = objective(x)\n",
    "#         # summarize the finding\n",
    "#         est, _ = surrogate(model, [[x]])\n",
    "#         print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "#         # add the data to the dataset\n",
    "#         X = vstack((X, [[x]]))\n",
    "#         y = vstack((y, [[actual]]))\n",
    "#         # update the model\n",
    "#         model.fit(X, y)\n",
    "\n",
    "#     # plot all samples and the final surrogate function\n",
    "#     plot(X, y, model)\n",
    "#     # best result\n",
    "#     ix = argmax(y)\n",
    "#     print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sobol sampling\n",
    "\n",
    "the idea behind this approach is to evaluate:\n",
    "1. if the function we are dealing with is convex, (in which case, all of the simplex methods will end up at the same place)\n",
    "2. if it's not convex, are there local solutions that are interesting to consider (perhaps are less sensitive, or better in some way we didn't anticipate?) the idea would be to visually inspect these solutions for their quality.\n",
    "\n",
    "\n",
    "#### refs:\n",
    "https://people.sc.fsu.edu/~jburkardt/py_src/sobol/sobol.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104b1c67e58d4e08836550d83999df7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='samps', max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d0e0c372124ecda7ad04ae455c023c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0.      , 0.001001, 0.002002, ..., 0.997998, 0.998999,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sobol import i4_sobol\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "class Sobol:\n",
    "    \"\"\"\n",
    "    the sobol opt class \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.n = 1000          #number of samples to evaluate\n",
    "        self.nBest = 10        #number to keep\n",
    "        self.xBest = []        #list of nBest x values\n",
    "        self.fxBest = []       #list of nBest obj function values\n",
    "        self.randomSeed = True #should sample seed be randomized?\n",
    "        \n",
    "        self.selectionMode = \"max_fx\" #str name of selection fxn [\"max_fx\", \"obj_var_tradeoff\"]\n",
    "        self.W_obj = 1                #importance parameter for objective fxn\n",
    "        self.W_dispersion = 1         #importance parameter for dispersion metric \n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def twoPointLine(x,x1,y1,x2,y2):\n",
    "        \"\"\"returns y given the formula of a line specified in 2 point form\"\"\"\n",
    "        return ((y2-y1)/(x2-x1))*(x - x1) + y1\n",
    "    \n",
    "    @staticmethod\n",
    "    def Sample(bounds,n,randomSeed = True):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "            bounds - [nx2] array of [max,min]\n",
    "            n - number of sample points requested\n",
    "            randomSeed - bool - start in a place other than 0\n",
    "        outputs:\n",
    "            samps - list of np.arrays  (so you can interate through them more easily)\n",
    "        \"\"\"\n",
    "        #calc the sobol inputs\n",
    "        ndims = bounds.shape[0]\n",
    "        upperbounds = bounds[:,0] ; lowerbounds = bounds[:,1]\n",
    "        if randomSeed: seed_0 = np.random.randint(0,10000)\n",
    "        else: seed_0 = 0\n",
    "        \n",
    "        #sample the unit hypercube\n",
    "        samps = [i4_sobol(ndims, seed)[0] for seed in range(seed_0,n + seed_0)]\n",
    "        #samps = np.array(samps)\n",
    "        \n",
    "        #shift and scale from the unit hypercube to the bounds rectangular prism\n",
    "        sl = []  #samps list\n",
    "        for sample in samps:\n",
    "            sn = np.zeros(ndims)  #sample new\n",
    "            for i,x in enumerate(sample):\n",
    "                x1 = 0 ; x2 = 1\n",
    "                y1 = lowerbounds[i] ; y2 = upperbounds[i]\n",
    "                sn[i] = Sobol.twoPointLine(x,x1,y1,x2,y2)\n",
    "            sl.append(sn)\n",
    "        \n",
    "        return sl\n",
    "    \n",
    "    def max_fx(self,xs,fxs):\n",
    "        \"\"\"\n",
    "        return the nBest results based only on the value of Fx\n",
    "        \"\"\"\n",
    "        np.argsort()\n",
    "        \n",
    "    \n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \"\"\"\n",
    "       discover interesting and good solutions at different locations within the space, \n",
    "       no optimization is performed strictly speaking, just structured exploration\n",
    "        \"\"\"\n",
    "        xs = Sobol.Sample(bounds,self.n,self.randomSeed)\n",
    "        fxs = [] \n",
    "        for x in xs:\n",
    "            fx.append(obj(x))\n",
    "        \n",
    "        return eval('self.' + self.selectionFxn + '(xs,fxs)')\n",
    "\n",
    "\n",
    "class SobolVis:\n",
    "    \"\"\"\n",
    "    just want to get a sense for what sampling a unit space\n",
    "    using sobol sampling looks like\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        _fig = go.Figure(data=[go.Scatter3d(z=[0],x=[0],y=[0], name = \"sampling\",mode=\"markers\",\n",
    "                                            marker = dict(size=10,color = np.linspace(0,1,1000),showscale=True))])\n",
    "        self.fig = go.FigureWidget(_fig)\n",
    "        n = widgets.IntSlider(min=1,max=1000,value=1,description='samps')\n",
    "        self.wdict = {\"n\":n}\n",
    "        \n",
    "        self.fig.update_layout(\n",
    "            autosize=False,\n",
    "            width = 800,\n",
    "            height= 800,\n",
    "            legend=dict(x=.025, y=.975),\n",
    "            margin=dict(l=0, r=20, t=0, b=0))\n",
    "        \n",
    "    def genSamps(self,n):\n",
    "        #how to use sobol\n",
    "        bounds = np.array([[.5,1,-1],[.25,-1,-3]]).T\n",
    "        samps = Sobol.Sample(bounds,n,randomSeed = False)\n",
    "        #samps = [i4_sobol(dim_num, seed)[0] for seed in range(n)]\n",
    "        samps = np.array(samps)\n",
    "        xs = samps[:,0] ; ys = samps[:,1] ; zs = samps[:,2]\n",
    "        return xs,ys,zs\n",
    "    \n",
    "    \n",
    "    def update(self,n=1):\n",
    "        fig = self.fig\n",
    "        with fig.batch_update():\n",
    "            #plot n sobol points, with coloring\n",
    "            xs,ys,zs = self.genSamps(n)\n",
    "            \n",
    "            fig.data[0]['x']= xs\n",
    "            fig.data[0]['y']= ys\n",
    "            fig.data[0]['z']= zs\n",
    "            \n",
    "            \n",
    "    def disp(self):\n",
    "        self.out = widgets.interactive_output(self.update, self.wdict)\n",
    "        display(self.wdict[\"n\"])\n",
    "        display(self.fig)\n",
    "        \n",
    "\n",
    "#interactive 3D sobol sampling visualization to get a sense of the algorithm \n",
    "if not asLibrary() and True:\n",
    "    vis = SobolVis()\n",
    "    vis.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS \n",
    "Broyden–Fletcher–Goldfarb–Shanno (BFGS) is a quazi-newton optimization method that uses the secant approach to find stationary points via locating the zeros of the gradient (jacobian) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "class BFGS:\n",
    "    def __init__(self):\n",
    "        self.mode = \"seeded\"   #[\"seeded\",\"sobol\",\"SA\"] \n",
    "        self.n = 1             #number of starting points\n",
    "        self.x0 = []           #incase you want to prime the algorithm, from outside manipulation\n",
    "        self.xBest = []        #list of n x values\n",
    "        self.fxBest = []       #list of n obj function values\n",
    "        self.res = []          #results of most recent optimization\n",
    "        \n",
    "    def optimize(self,obj,bounds,constraints): #refactor to remove this code repetition.\n",
    "        \n",
    "        #specify the bounds:\n",
    "        bnds = Bounds(bounds[:,1],bounds[:,0],keep_feasible=True)\n",
    "        \n",
    "        #specify the fixed step size (epsilon):\n",
    "        eps = (bounds[:,0] - bounds[:,1])/10000\n",
    "        \n",
    "        #make a maximum into a minimum\n",
    "        min_obj = lambda x: -1 * obj(x)\n",
    "        \n",
    "        if self.mode == \"seeded\":\n",
    "            self.res = minimize(min_obj,\n",
    "                                self.x0[0],\n",
    "                                method='BFGS',\n",
    "                                jac = False,\n",
    "                                bounds = bnds,\n",
    "                                options={'gtol': 1e-3,\n",
    "                                         'disp': True,\n",
    "                                         'eps': eps})\n",
    "                                        #'finite_diff_rel_step':finite_diff_rel_step})\n",
    "            self.xBest.append(self.res.x)\n",
    "            self.fxBest.append(1)\n",
    "            \n",
    "        elif self.mode == \"sobol\":\n",
    "            samps = Sobol.Sample(bounds,self.n,randomSeed = True)\n",
    "            for x0 in samps:\n",
    "                self.res = minimize(obj, x0, method='BFGS',\n",
    "                           options={'gtol': 1e-6, 'disp': True})\n",
    "                self.xBest.append(self.res.x)\n",
    "                self.fxBest.append(1)\n",
    "        \n",
    "        return self.xBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "optimize() missing 2 required positional arguments: 'bounds' and 'constraints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-f986983710da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetBounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxConstraints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtester\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxBest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: optimize() missing 2 required positional arguments: 'bounds' and 'constraints'"
     ]
    }
   ],
   "source": [
    "#simulated anealing algorithm must have the following functions: \n",
    "# the feasable state space\n",
    "# the Energetic function (which is the objective function) E()\n",
    "# the candidate generator procedure (neighbor(x))\n",
    "#        -generation of random candidate vector, with variable magnitude?\n",
    "#         aniostropic exploration is better!!!\n",
    "#thoughts for how I might solve this problem - \n",
    "#         boundry check or only sampling within the boundry seems a good strategy. \n",
    "#        -moving in one direction at at time. \n",
    "\n",
    "# acceptance probability function P()\n",
    "# anealing schedule - number, number of anealing cycles, cooling rate\n",
    "# some termination condition - total execution time or number of interations\n",
    "# presensce of and number of restarts, deterministic or otherwise? \n",
    "\n",
    "#of these, cooling schedule and neighbor seem the most important functions\n",
    "\n",
    "\n",
    "class SA:\n",
    "    def __init__(self):\n",
    "        self.nIter = 1000;                     #total number of iterations to perform\n",
    "        self.nResets = 3                       #number of resets to best \n",
    "        self.brt = self._brt()                 #trial numbers during which to reset to best\n",
    "        self.dist = \"uniform\"                  #neighborhood sampling method \n",
    "        self.aMode = \"exp\"                     #Annealing mode [\"exp\",\"linear\",\"stepped\"]\n",
    "        self.nMode = \"linear\"                  #neighborhood Mode\n",
    "        self.T = 1                             #temperature variable on [1-0)\n",
    "        self.N = 1                             #neighborhood size coefficient [1-0)\n",
    "        self.C_half = 200                      #half-life cooling              [trials]\n",
    "        self.N_half = 150                      #half-life of neighborhood size [trials]\n",
    "        self.fxBest = 0                        #best encountered function value\n",
    "        self.xBest = []                        #location of best value\n",
    "        self.dbg = False                        #save variables for debugging\n",
    "        self.xCache  = []                      #storage for x\n",
    "        self.FxCache = []                      #storage for Fx\n",
    "        self.updateReports = True              #should we print out an update of how the optimization is progressing?\n",
    "        self.updateCount = 10                  #number of updates\n",
    "        \n",
    "        \n",
    "    def setBounds(self,bcs):\n",
    "        self.x_max = bcs[:,0]                  #upper limits on box constraints for x variable\n",
    "        self.x_min = bcs[:,1]                  #lower limits on box constraints for x variable\n",
    "        \n",
    "    def _center(self,x_max,x_min):\n",
    "        \"\"\"\n",
    "        find  the center of a box defined by limits\n",
    "        \"\"\"\n",
    "        return [(x_max[i] + x_min[i])/2 for i in range(len(x_max))]\n",
    "    \n",
    "    def _twoPointLine(self,x,x1,y1,x2,y2):\n",
    "        \"\"\"\n",
    "        returns y given the formula of a line specified in 2 point form\n",
    "        \"\"\"\n",
    "        return ((y2-y1)/(x2-x1))*(x - x1) + y1\n",
    "    \n",
    "    def _brt(self):\n",
    "        \"\"\"\n",
    "        calculate the best reset trials, evenly distribute in n_iter\n",
    "        \"\"\"\n",
    "        return np.random.randint(low  = int(self.nIter/5),\n",
    "                                 high = self.nIter,\n",
    "                                 size = self.nResets)\n",
    "        \n",
    "            \n",
    "    def sample(self,x):\n",
    "        \"\"\"\n",
    "        sample the space for the next sample based on the neighborhood\n",
    "        function\n",
    "        input:\n",
    "            x\n",
    "        output:\n",
    "            x_new\n",
    "        \"\"\"\n",
    "        #define the (ever-shrinking) neighborhood bounding box\n",
    "        w = self.N * ((self.x_max - self.x_min)/2) \n",
    "        nx_max = x + w\n",
    "        nx_min = x - w\n",
    "        \n",
    "        #define the combined bounding box as an intersection between\n",
    "        #the box constraints and the neighborhood box - a mini-max problem\n",
    "        cx_max = np.amin(np.vstack((self.x_max,nx_max)),axis = 0)\n",
    "        cx_min =  np.max(np.vstack((self.x_min,nx_min)),axis = 0)\n",
    "        \n",
    "#         for i in range(len(self.x_max)):\n",
    "#             cx_max[i] = min(self.x_max,nx_max[i])\n",
    "#             cx_min[i] = max(self.x_min,nx_min[i])\n",
    "        \n",
    "        #sample from the combined box, according to the appropriate distribution\n",
    "        if self.dist == \"uniform\": \n",
    "            x_new = np.random.uniform(cx_min,cx_max) #vectorized\n",
    "            \n",
    "        if self.dist == \"normal\":\n",
    "            pass\n",
    "#             zScore = 1.645 #95% confidence interval\n",
    "#             x_new = []\n",
    "#             while len(x_new) > len(self.x_min):\n",
    "#                 x = np.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "#                 if abs(x) < zScore:\n",
    "#                     x_new.append(x)\n",
    "#             c_range = cx_max - cx_min\n",
    "            \n",
    " \n",
    "        return x_new\n",
    "\n",
    "    def optimize(self,obj,bounds,constraints):\n",
    "        \n",
    "        #set box constraints\n",
    "        bcs = bounds()\n",
    "        self.setBounds(bcs)\n",
    "        \n",
    "        #init x0 and fx0\n",
    "        x0 =  self._center(self.x_max,self.x_min)\n",
    "        fx0 = obj(x0)\n",
    "        \n",
    "        for n in range(self.nIter + 1):\n",
    "            x = self.sample(x0)\n",
    "            fx = obj(x)\n",
    "            \n",
    "            #if better, always keep\n",
    "            if fx > fx0:\n",
    "                x0 = x ; fx0 = fx\n",
    "                \n",
    "            #probabalistically accept worse answer\n",
    "            else:\n",
    "                Δf = fx - fx0\n",
    "                r = np.random.random()\n",
    "                if r < np.exp(Δf/self.T):\n",
    "                    fx0 = fx ; x0 = x\n",
    "                    #print(x)\n",
    "                else:\n",
    "                    pass\n",
    "             \n",
    "            \n",
    "            #maintain best (for restarts, if used)\n",
    "            if fx > self.fxBest:\n",
    "                self.xBest = x  ; self.fxBest = fx \n",
    "                \n",
    "            #do a best restart:\n",
    "            if n in self.brt:\n",
    "                  x0 = self.xBest ; fx0 = self.fxBest \n",
    "            \n",
    "            #decrease temperature and neighborhood size\n",
    "            if self.aMode == \"exp\": self.T = .5**(n/self.C_half)\n",
    "            if self.nMode == \"exp\": self.N = .5**(n/self.N_half)\n",
    "            \n",
    "            if self.aMode == \"Linear\": self.T = self._twoPointLine(n,0,1,self.nIter,0)\n",
    "            if self.nMode == \"Linear\": self.N = self._twoPointLine(n,0,1,self.nIter,0)\n",
    "                \n",
    "                  \n",
    "            #store debugging vars\n",
    "            if self.dbg:\n",
    "                self.xCache.append(x0[0])\n",
    "                self.FxCache.append(fx0[0])\n",
    "                \n",
    "            #give updates\n",
    "            if self.updateReports:\n",
    "                if n % ((self.nIter) / 10) == 0:\n",
    "                    print(\"on iteration %d\" %n)\n",
    "        \n",
    "        return x0\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if not asLibrary():\n",
    "#     #plot\n",
    "#     tester = testObjFxn()\n",
    "#     boxConstraints = np.array([[1,0]])\n",
    "#     sa = SA()\n",
    "#     sa.dbg = True\n",
    "#     sa.setBounds(boxConstraints)\n",
    "\n",
    "#     x0,fx0 = sa.optimize(tester.f)\n",
    "#     print(x0,fx0)\n",
    "#     print(sa.xBest)\n",
    "    \n",
    "#     tester.pltSampleHistory(sa.xCache,sa.FxCache)\n",
    "    \n",
    "#     #%timeit sa.optimize(tester.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes:\n",
    "\n",
    "* instead of optimization per se, you could try something where you take the best solutions from a variety of locations within the space, so do a giant sobol sample on the space, and then choose the 100 best solutions that are the most different in terms of euclidian distance within the space, something like that. \n",
    "* I think we might want to add the ability to save general information within the picking process. so we could save an experiment like the one above. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
